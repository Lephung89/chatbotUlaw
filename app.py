import streamlit as st
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain_google_genai import GoogleGenerativeAI
from langchain_openai import OpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
import os
import pickle
import json
import pandas as pd
from datetime import datetime
import re
import glob
from pathlib import Path
from dotenv import load_dotenv

# Cáº¥u hÃ¬nh trang
st.set_page_config(
    page_title="Chatbot TÆ° Váº¥n - Äáº¡i há»c Luáº­t TPHCM",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS tÃ¹y chá»‰nh nÃ¢ng cao
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    * {
        font-family: 'Inter', sans-serif;
    }
    
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 50%, #1e3c72 100%);
        padding: 2rem;
        border-radius: 20px;
        color: black;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(30, 60, 114, 0.3);
        position: relative;
        overflow: hidden;
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
        animation: shimmer 3s infinite;
    }
    
    @keyframes shimmer {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    
    .main-header h1 {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        position: relative;
        z-index: 1;
    }
    
    .main-header h3 {
        font-size: 1.3rem;
        font-weight: 500;
        margin-bottom: 0.5rem;
        opacity: 0.9;
        position: relative;
        z-index: 1;
    }
    
    .main-header p {
        font-size: 1rem;
        opacity: 0.8;
        position: relative;
        z-index: 1;
    }
    
    .chat-message {
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1.5rem 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        backdrop-filter: blur(10px);
        transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    
    .chat-message:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    
    .user-message {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 5px solid #2196f3;
        color: #1565c0;
    }
    
    .assistant-message {
        background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
        border-left: 5px solid #9c27b0;
        color: #6a1b9a;
    }
    
    .sidebar-info {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
    }
    
    .file-status {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #4caf50;
        box-shadow: 0 2px 8px rgba(76, 175, 80, 0.2);
    }
    
    .metric-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        border: 1px solid #e9ecef;
        margin: 0.5rem 0;
        transition: transform 0.2s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.15);
    }
    
    .metric-value {
        font-size: 2rem;
        font-weight: 700;
        color: #1e3c72;
        margin-bottom: 0.5rem;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #6c757d;
        font-weight: 500;
    }
    
    .info-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
        border: 1px solid #ffb74d;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(255, 183, 77, 0.2);
    }
    
    .success-card {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        border: 1px solid #4caf50;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(76, 175, 80, 0.2);
    }
    
    .warning-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffcc80 100%);
        border: 1px solid #ff9800;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(255, 152, 0, 0.2);
    }
    
    .category-badge {
        display: inline-block;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 600;
        margin: 0.2rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    .badge-tuyensinh {
        background: linear-gradient(135deg, #e3f2fd 0%, #90caf9 100%);
        color: #1565c0;
    }
    
    .badge-hocphi {
        background: linear-gradient(135deg, #e8f5e8 0%, #a5d6a7 100%);
        color: #2e7d32;
    }
    
    .badge-chuongtrinh {
        background: linear-gradient(135deg, #f3e5f5 0%, #ce93d8 100%);
        color: #6a1b9a;
    }
    
    .badge-sinhhoat {
        background: linear-gradient(135deg, #fff3e0 0%, #ffcc80 100%);
        color: #e65100;
    }
    
    .badge-hotro {
        background: linear-gradient(135deg, #fce4ec 0%, #f8bbd9 100%);
        color: #c2185b;
    }
    
    .badge-totnghiep {
        background: linear-gradient(135deg, #e0f2f1 0%, #80cbc4 100%);
        color: #00695c;
    }
    
    .quick-actions {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 1rem;
        margin: 1.5rem 0;
    }
    
    .action-button {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border: 2px solid #e9ecef;
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        cursor: pointer;
        transition: all 0.3s ease;
        text-decoration: none;
        color: #495057;
    }
    
    .action-button:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 25px rgba(0,0,0,0.15);
        border-color: #2196f3;
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
    }
    
    .action-icon {
        font-size: 2rem;
        margin-bottom: 0.5rem;
        display: block;
    }
    
    .footer {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-top: 3rem;
        text-align: center;
    }
    
    .footer-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
        gap: 2rem;
        margin-bottom: 1rem;
    }
    
    .footer-section h4 {
        color: #90caf9;
        margin-bottom: 1rem;
        font-weight: 600;
    }
    
    .footer-section p {
        margin-bottom: 0.5rem;
        opacity: 0.9;
    }
    
    .stSelectbox > div > div {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border-radius: 10px;
        border: 2px solid #e9ecef;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #2196f3 0%, #1976d2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #1976d2 0%, #1565c0 100%);
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(33, 150, 243, 0.3);
    }
    
    .chat-input {
        border-radius: 25px !important;
        border: 2px solid #e9ecef !important;
        padding: 1rem 1.5rem !important;
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%) !important;
    }
    
    .stChatInput > div > div > textarea {
        border-radius: 25px;
        border: 2px solid #e9ecef;
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
    }
    
    .loading-container {
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 2rem;
    }
    
    .loading-spinner {
        width: 40px;
        height: 40px;
        border: 4px solid #e9ecef;
        border-top: 4px solid #2196f3;
        border-radius: 50%;
        animation: spin 1s linear infinite;
    }
    
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 1.5rem;
        margin: 2rem 0;
    }
    
    .feature-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border: 1px solid #e9ecef;
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 25px rgba(0,0,0,0.15);
    }
    
    .feature-icon {
        font-size: 3rem;
        margin-bottom: 1rem;
        color: #2196f3;
    }
    
    .feature-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #1e3c72;
        margin-bottom: 0.5rem;
    }
    
    .feature-description {
        color: #6c757d;
        font-size: 0.9rem;
        line-height: 1.5;
    }
</style>
#MainMenu {visibility: hidden;}
""", unsafe_allow_html=True)

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()
grok_api_key = os.getenv("GROK_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")

# Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n
DOCUMENTS_PATH = "documents"
VECTORSTORE_PATH = "vectorstore"
CACHE_PATH = "cache"

# Táº¡o cÃ¡c thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
for path in [DOCUMENTS_PATH, VECTORSTORE_PATH, CACHE_PATH]:
    Path(path).mkdir(exist_ok=True)

# Template prompt chuyÃªn biá»‡t cho tÆ° váº¥n tuyá»ƒn sinh
COUNSELING_PROMPT_TEMPLATE = """
Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n tuyá»ƒn sinh vÃ  cÃ´ng tÃ¡c sinh viÃªn cá»§a TrÆ°á»ng Äáº¡i há»c Luáº­t ThÃ nh phá»‘ Há»“ ChÃ­ Minh.
HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p vÃ  kiáº¿n thá»©c chuyÃªn mÃ´n.

NguyÃªn táº¯c tráº£ lá»i:
1. ThÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  dá»… hiá»ƒu
2. Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c, cá»¥ thá»ƒ vá» Äáº¡i há»c Luáº­t TPHCM
3. ÄÆ°a ra lá»i khuyÃªn phÃ¹ há»£p vá»›i tá»«ng trÆ°á»ng há»£p
4. HÆ°á»›ng dáº«n cÃ¡c bÆ°á»›c cáº§n thiáº¿t náº¿u cÃ³
5. LuÃ´n khuyáº¿n khÃ­ch vÃ  táº¡o Ä‘á»™ng lá»±c tÃ­ch cá»±c
6. Cung cáº¥p thÃ´ng tin liÃªn há»‡ cá»¥ thá»ƒ khi cáº§n thiáº¿t

ThÃ´ng tin tham kháº£o: {context}

Lá»‹ch sá»­ há»™i thoáº¡i: {chat_history}

CÃ¢u há»i cá»§a sinh viÃªn/thÃ­ sinh: {question}

Tráº£ lá»i (báº±ng tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p):
"""

# Khá»Ÿi táº¡o embeddings vá»›i model phÃ¹ há»£p tiáº¿ng Viá»‡t
@st.cache_resource
def load_embeddings():
    return HuggingFaceEmbeddings(
        model_name="keepitreal/vietnamese-sbert",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

embeddings = load_embeddings()

# HÃ m láº¥y danh sÃ¡ch file tá»« thÆ° má»¥c documents
def get_document_files():
    """Láº¥y danh sÃ¡ch táº¥t cáº£ file trong thÆ° má»¥c documents"""
    supported_extensions = ['*.pdf', '*.docx', '*.txt']
    files = []
    
    for ext in supported_extensions:
        files.extend(glob.glob(os.path.join(DOCUMENTS_PATH, '**', ext), recursive=True))
    
    return files

# HÃ m táº¡o hash cho file Ä‘á»ƒ kiá»ƒm tra thay Ä‘á»•i
def get_file_hash(file_path):
    """Táº¡o hash cho file Ä‘á»ƒ kiá»ƒm tra thay Ä‘á»•i"""
    stat = os.stat(file_path)
    return f"{stat.st_mtime}_{stat.st_size}"

# HÃ m kiá»ƒm tra cache vector store
def load_cached_vectorstore():
    """Load vector store tá»« cache náº¿u cÃ³"""
    cache_file = os.path.join(VECTORSTORE_PATH, "vectorstore.pkl")
    metadata_file = os.path.join(VECTORSTORE_PATH, "metadata.json")
    
    if not (os.path.exists(cache_file) and os.path.exists(metadata_file)):
        return None, {}
    
    try:
        # Load metadata
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # Load vector store
        with open(cache_file, 'rb') as f:
            vectorstore = pickle.load(f)
        
        return vectorstore, metadata
    except Exception as e:
        st.warning(f"KhÃ´ng thá»ƒ load cache: {e}")
        return None, {}

# HÃ m lÆ°u vector store vÃ o cache
def save_vectorstore_cache(vectorstore, metadata):
    """LÆ°u vector store vÃ  metadata vÃ o cache"""
    try:
        cache_file = os.path.join(VECTORSTORE_PATH, "vectorstore.pkl")
        metadata_file = os.path.join(VECTORSTORE_PATH, "metadata.json")
        
        # LÆ°u vector store
        with open(cache_file, 'wb') as f:
            pickle.dump(vectorstore, f)
        
        # LÆ°u metadata
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        st.error(f"Lá»—i lÆ°u cache: {e}")
        return False

# HÃ m kiá»ƒm tra xem cÃ³ cáº§n rebuild vector store khÃ´ng
def need_rebuild_vectorstore():
    """Kiá»ƒm tra xem cÃ³ cáº§n rebuild vector store khÃ´ng"""
    current_files = get_document_files()
    
    if not current_files:
        return False, {}, []
    
    # Táº¡o metadata hiá»‡n táº¡i
    current_metadata = {}
    for file_path in current_files:
        current_metadata[file_path] = get_file_hash(file_path)
    
    # Load cached metadata
    _, cached_metadata = load_cached_vectorstore()
    
    # So sÃ¡nh
    if current_metadata != cached_metadata.get('files', {}):
        return True, current_metadata, current_files
    
    return False, current_metadata, current_files

# HÃ m xá»­ lÃ½ file tÃ i liá»‡u
def process_documents(file_paths):
    """Xá»­ lÃ½ danh sÃ¡ch file tÃ i liá»‡u"""
    documents = []
    processed_files = []
    failed_files = []
    
    for file_path in file_paths:
        try:
            file_extension = Path(file_path).suffix.lower()
            
            if file_extension == ".pdf":
                loader = PyPDFLoader(file_path)
            elif file_extension == ".docx":
                loader = Docx2txtLoader(file_path)
            elif file_extension == ".txt":
                loader = TextLoader(file_path, encoding='utf-8')
            else:
                failed_files.append(f"{file_path} (khÃ´ng há»— trá»£)")
                continue
            
            docs = loader.load()
            
            # ThÃªm metadata
            for doc in docs:
                doc.metadata['source_file'] = os.path.basename(file_path)
                doc.metadata['file_path'] = file_path
                doc.metadata['processed_time'] = datetime.now().isoformat()
            
            documents.extend(docs)
            processed_files.append(file_path)
            
        except Exception as e:
            failed_files.append(f"{file_path} (lá»—i: {str(e)})")
    
    return documents, processed_files, failed_files

# HÃ m táº¡o vector store
def create_vector_store(documents):
    """Táº¡o vector store tá»« documents"""
    if not documents:
        return None
        
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=['\n\n', '\n', '.', '!', '?', ';', ':', ' ']
    )
    texts = text_splitter.split_documents(documents)
    
    # Lá»c bá» cÃ¡c chunk quÃ¡ ngáº¯n
    texts = [text for text in texts if len(text.page_content.strip()) > 50]
    
    if not texts:
        return None
        
    vector_store = FAISS.from_documents(texts, embeddings)
    return vector_store

# HÃ m khá»Ÿi táº¡o hoáº·c load vector store
@st.cache_resource
def initialize_vectorstore():
    """Khá»Ÿi táº¡o hoáº·c load vector store"""
    need_rebuild, current_metadata, current_files = need_rebuild_vectorstore()
    
    if not need_rebuild:
        # Load tá»« cache
        vectorstore, cached_metadata = load_cached_vectorstore()
        if vectorstore:
            return vectorstore, cached_metadata.get('files', {}), cached_metadata.get('stats', {})
    
    # Rebuild vector store
    if not current_files:
        return None, {}, {}
    
    with st.spinner("ğŸ”„ Äang xá»­ lÃ½ tÃ i liá»‡u..."):
        documents, processed_files, failed_files = process_documents(current_files)
        
        if not documents:
            return None, {}, {}
        
        vectorstore = create_vector_store(documents)
        
        if vectorstore:
            # Táº¡o metadata Ä‘á»ƒ lÆ°u
            metadata_to_save = {
                'files': current_metadata,
                'stats': {
                    'total_files': len(current_files),
                    'processed_files': len(processed_files),
                    'failed_files': len(failed_files),
                    'total_chunks': vectorstore.index.ntotal,
                    'last_updated': datetime.now().isoformat()
                },
                'processed_files': processed_files,
                'failed_files': failed_files
            }
            
            # LÆ°u cache
            save_vectorstore_cache(vectorstore, metadata_to_save)
            
            return vectorstore, current_metadata, metadata_to_save['stats']
    
    return None, {}, {}

# HÃ m phÃ¢n loáº¡i cÃ¢u há»i
def classify_question(question):
    """PhÃ¢n loáº¡i cÃ¢u há»i Ä‘á»ƒ Ä‘Æ°a ra pháº£n há»“i phÃ¹ há»£p"""
    question_lower = question.lower()
    
    categories = {
        "Tuyá»ƒn sinh": ["tuyá»ƒn sinh", "Ä‘Äƒng kÃ½", "há»“ sÆ¡", "Ä‘iá»ƒm chuáº©n", "xÃ©t tuyá»ƒn", "ká»³ thi", "thá»§ tá»¥c", "Ä‘Äƒng kÃ­", "ná»™p há»“ sÆ¡"],
        "Há»c phÃ­": ["há»c phÃ­", "chi phÃ­", "miá»…n giáº£m", "há»c bá»•ng", "trá»£ cáº¥p", "tÃ i chÃ­nh", "phÃ­", "tiá»n"],
        "ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o": ["chÆ°Æ¡ng trÃ¬nh", "mÃ´n há»c", "tÃ­n chá»‰", "khoa", "ngÃ nh", "thá»i khÃ³a biá»ƒu", "há»c táº­p", "Ä‘Ã o táº¡o"],
        "Sinh hoáº¡t sinh viÃªn": ["cÃ¢u láº¡c bá»™", "hoáº¡t Ä‘á»™ng", "thá»ƒ thao", "vÄƒn hÃ³a", "tÃ¬nh nguyá»‡n", "sinh hoáº¡t", "sá»± kiá»‡n"],
        "Há»— trá»£ sinh viÃªn": ["tÆ° váº¥n", "há»— trá»£", "kÃ½ tÃºc xÃ¡", "thÆ° viá»‡n", "cÆ¡ sá»Ÿ váº­t cháº¥t", "ktx", "á»Ÿ", "chá»— á»Ÿ"],
        "Tá»‘t nghiá»‡p": ["tá»‘t nghiá»‡p", "báº±ng cáº¥p", "thá»±c táº­p", "viá»‡c lÃ m", "nghá» nghiá»‡p", "ra trÆ°á»ng", "thá»±c táº¿"]
    }
    
    for category, keywords in categories.items():
        if any(keyword in question_lower for keyword in keywords):
            return category
    return "KhÃ¡c"

# HÃ m táº¡o badge cho danh má»¥c
def get_category_badge(category):
    """Táº¡o badge HTML cho danh má»¥c cÃ¢u há»i"""
    badge_classes = {
        "Tuyá»ƒn sinh": "badge-tuyensinh",
        "Há»c phÃ­": "badge-hocphi", 
        "ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o": "badge-chuongtrinh",
        "Sinh hoáº¡t sinh viÃªn": "badge-sinhhoat",
        "Há»— trá»£ sinh viÃªn": "badge-hotro",
        "Tá»‘t nghiá»‡p": "badge-totnghiep"
    }
    
    badge_class = badge_classes.get(category, "badge-tuyensinh")
    return f'<span class="category-badge {badge_class}">{category}</span>'

# HÃ m khá»Ÿi táº¡o Conversational Retrieval Chain
def create_conversational_chain(vector_store, llm):
    prompt = PromptTemplate(
        template=COUNSELING_PROMPT_TEMPLATE,
        input_variables=["context", "chat_history", "question"]
    )
    
    memory = ConversationBufferWindowMemory(
        k=5,
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(search_kwargs={"k": 5}),
        memory=memory,
        return_source_documents=True,
        combine_docs_chain_kwargs={"prompt": prompt}
    )

# HÃ m káº¿t ná»‘i LLM
@st.cache_resource
def get_gemini_llm():
    return GoogleGenerativeAI(
        model="gemini-1.5-flash",
        google_api_key=gemini_api_key,
        temperature=0.3,
        max_output_tokens=1000
    )

@st.cache_resource
def get_grok_llm():
    return OpenAI(
        api_key=grok_api_key,
        base_url="https://api.x.ai/v1",
        model="grok-3",
        temperature=0.3,
        max_tokens=1000
    )

# HÃ m tráº£ lá»i tá»« API bÃªn ngoÃ i
def answer_from_external_api(prompt, llm, question_category):
    enhanced_prompt = f"""
    Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n {question_category.lower()} cá»§a TrÆ°á»ng Äáº¡i há»c Luáº­t ThÃ nh phá»‘ Há»“ ChÃ­ Minh.
    
    CÃ¢u há»i: {prompt}
    
    HÃ£y tráº£ lá»i má»™t cÃ¡ch thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  há»¯u Ã­ch. 
    Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vá» Äáº¡i há»c Luáº­t TPHCM.
    Náº¿u khÃ´ng cÃ³ thÃ´ng tin cá»¥ thá»ƒ, hÃ£y Ä‘Æ°a ra lá»i khuyÃªn chung phÃ¹ há»£p vÃ  
    khuyáº¿n khÃ­ch liÃªn há»‡ phÃ²ng ban cÃ³ liÃªn quan Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ chi tiáº¿t hÆ¡n.
    
    ThÃ´ng tin liÃªn há»‡:
    - PhÃ²ng Tuyá»ƒn sinh: 1900 5555 14 hoáº·c 0879 5555 14
    - PhÃ²ng CÃ´ng tÃ¡c sinh viÃªn:
    - Email: tuyensinh@hcmulaw.edu.vn
    - Äá»‹a chá»‰: 2 Nguyá»…n Táº¥t ThÃ nh, PhÆ°á»ng 12, Quáº­n 4, TP.HCM
    """
    
    try:
        if isinstance(llm, GoogleGenerativeAI):
            response = llm.invoke(enhanced_prompt)
        else:
            response = llm.invoke(enhanced_prompt)
        return response
    except Exception as e:
        return f"Xin lá»—i, tÃ´i gáº·p má»™t chÃºt trá»¥c tráº·c ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ trá»±c tiáº¿p vá»›i phÃ²ng tÆ° váº¥n theo sá»‘ (028) 3838 5052. Lá»—i: {str(e)}"

# HÃ m lÆ°u lá»‹ch sá»­ há»™i thoáº¡i
def save_chat_history(user_question, bot_response, question_category):
    if 'chat_logs' not in st.session_state:
        st.session_state.chat_logs = []
    
    st.session_state.chat_logs.append({
        'timestamp': datetime.now().isoformat(),
        'user_question': user_question,
        'bot_response': bot_response,
        'category': question_category
    })

# HÃ m hiá»ƒn thá»‹ thá»‘ng kÃª
def display_stats_cards(stats):
    """Hiá»ƒn thá»‹ thá»‘ng kÃª dÆ°á»›i dáº¡ng cards Ä‘áº¹p"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">ğŸ“„ {stats.get('total_files', 0)}</div>
            <div class="metric-label">Tá»•ng sá»‘ file</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">âœ… {stats.get('processed_files', 0)}</div>
            <div class="metric-label">ÄÃ£ xá»­ lÃ½</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">ğŸ“Š {stats.get('total_chunks', 0)}</div>
            <div class="metric-label">Chunks dá»¯ liá»‡u</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">âŒ {stats.get('failed_files', 0)}</div>
            <div class="metric-label">Lá»—i xá»­ lÃ½</div>
        </div>
        """, unsafe_allow_html=True)

# HÃ m hiá»ƒn thá»‹ cÃ¡c cÃ¢u há»i gá»£i Ã½
def display_quick_questions():
    """Hiá»ƒn thá»‹ cÃ¡c cÃ¢u há»i gá»£i Ã½"""
    st.markdown("### ğŸ’¡ CÃ¢u há»i thÆ°á»ng gáº·p")
    
    quick_questions = [
        "ğŸ“ Thá»§ tá»¥c Ä‘Äƒng kÃ½ xÃ©t tuyá»ƒn nhÆ° tháº¿ nÃ o?",
        "ğŸ’° Há»c phÃ­ cá»§a trÆ°á»ng lÃ  bao nhiá»u?", 
        "ğŸ“š CÃ¡c ngÃ nh há»c cá»§a trÆ°á»ng cÃ³ gÃ¬?",
        "ğŸ  TrÆ°á»ng cÃ³ kÃ½ tÃºc xÃ¡ khÃ´ng?",
        "ğŸ“ CÆ¡ há»™i viá»‡c lÃ m sau tá»‘t nghiá»‡p?",
        "ğŸ“ ThÃ´ng tin liÃªn há»‡ tÆ° váº¥n?"
    ]
    
    cols = st.columns(2)
    for i, question in enumerate(quick_questions):
        with cols[i % 2]:
            if st.button(question, key=f"quick_{i}", use_container_width=True):
                st.session_state.suggested_question = question.split(" ", 1)[1]  # Bá» emoji

# HÃ m hiá»ƒn thá»‹ cÃ¡c tÃ­nh nÄƒng
def display_features():
    """Hiá»ƒn thá»‹ cÃ¡c tÃ­nh nÄƒng cá»§a chatbot"""
    st.markdown("### ğŸš€ TÃ­nh nÄƒng há»— trá»£")
    
    st.markdown("""
    <div class="feature-grid">
        <div class="feature-card">
            <div class="feature-icon">ğŸ¯</div>
            <div class="feature-title">TÆ° váº¥n tuyá»ƒn sinh</div>
            <div class="feature-description">HÆ°á»›ng dáº«n chi tiáº¿t vá» thá»§ tá»¥c Ä‘Äƒng kÃ½, Ä‘iá»ƒm chuáº©n, phÆ°Æ¡ng thá»©c xÃ©t tuyá»ƒn</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸ’¡</div>
            <div class="feature-title">Há»— trá»£ sinh viÃªn</div>
            <div class="feature-description">ThÃ´ng tin vá» kÃ½ tÃºc xÃ¡, há»c bá»•ng, hoáº¡t Ä‘á»™ng ngoáº¡i khÃ³a</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸ“š</div>
            <div class="feature-title">ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o</div>
            <div class="feature-description">Chi tiáº¿t vá» cÃ¡c ngÃ nh há»c, mÃ´n há»c, tÃ­n chá»‰ vÃ  káº¿ hoáº¡ch há»c táº­p</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸŒŸ</div>
            <div class="feature-title">TÆ° váº¥n nghá» nghiá»‡p</div>
            <div class="feature-description">Äá»‹nh hÆ°á»›ng nghá» nghiá»‡p, cÆ¡ há»™i viá»‡c lÃ m sau tá»‘t nghiá»‡p</div>
        </div>
    </div>
    """, unsafe_allow_html=True)

# Giao diá»‡n chÃ­nh
def main():
    # Header vá»›i animation
    st.markdown("""
    <div class="main-header">
        <h1>âš–ï¸ Chatbot TÆ° Váº¥n Tuyá»ƒn Sinh</h1>
        <h3>TrÆ°á»ng Äáº¡i há»c Luáº­t ThÃ nh phá»‘ Há»“ ChÃ­ Minh</h3>
        <p>ğŸ¤– Há»— trá»£ 24/7 | ğŸ’¬ TÆ° váº¥n chuyÃªn nghiá»‡p | ğŸ“ ThÃ´ng tin chÃ­nh xÃ¡c</p>
    </div>
    """, unsafe_allow_html=True)

    # Sidebar cáº£i tiáº¿n
    with st.sidebar:
        st.markdown("## ğŸ› ï¸ Báº£ng Ä‘iá»u khiá»ƒn")
        
        # ThÃ´ng tin há»‡ thá»‘ng
        st.markdown("### ğŸ“Š Tráº¡ng thÃ¡i há»‡ thá»‘ng")
        
        # Khá»Ÿi táº¡o vector store
        with st.spinner("ğŸ”„ Äang khá»Ÿi táº¡o há»‡ thá»‘ng..."):
            vectorstore, file_metadata, stats = initialize_vectorstore()
            st.session_state.vector_store = vectorstore
            st.session_state.file_stats = stats
        
        if stats:
            st.markdown("""
            <div class="success-card">
                <h4>âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!</h4>
                <p>Táº¥t cáº£ tÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  sáºµn sÃ ng phá»¥c vá»¥.</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Hiá»ƒn thá»‹ thá»‘ng kÃª mini
            display_stats_cards(stats)
            
            # Thá»i gian cáº­p nháº­t
            if 'last_updated' in stats:
                last_updated = datetime.fromisoformat(stats['last_updated'])
                st.markdown(f"""
                <div class="info-card">
                    <strong>ğŸ•’ Cáº­p nháº­t cuá»‘i:</strong><br>
                    {last_updated.strftime('%d/%m/%Y lÃºc %H:%M')}
                </div>
                """, unsafe_allow_html=True)
            
            # NÃºt refresh vá»›i style
            if st.button("ğŸ”„ LÃ m má»›i tÃ i liá»‡u", type="primary", use_container_width=True):
                st.cache_resource.clear()
                st.rerun()
        else:
            st.markdown("""
            <div class="warning-card">
                <h4>âš ï¸ KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u!</h4>
                <p>Vui lÃ²ng thÃªm file tÃ i liá»‡u vÃ o thÆ° má»¥c <code>documents</code></p>
            </div>
            """, unsafe_allow_html=True)
            
            # HÆ°á»›ng dáº«n chi tiáº¿t
            with st.expander("ğŸ“‹ HÆ°á»›ng dáº«n thÃªm tÃ i liá»‡u", expanded=True):
                st.markdown(f"""
                **CÃ¡c bÆ°á»›c thÃªm tÃ i liá»‡u:**
                1. ğŸ“ Táº¡o thÆ° má»¥c `{DOCUMENTS_PATH}` 
                2. ğŸ“„ Copy file PDF, DOCX, TXT vÃ o thÆ° má»¥c
                3. ğŸ”„ Nháº¥n "LÃ m má»›i tÃ i liá»‡u"
                
                **Äá»‹nh dáº¡ng há»— trá»£:**
                - ğŸ“„ PDF files (*.pdf)
                - ğŸ“ Word documents (*.docx)  
                - ğŸ“‹ Text files (*.txt)
                
                **LÆ°u Ã½:** File nÃªn chá»©a thÃ´ng tin vá» tuyá»ƒn sinh, chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o, sinh hoáº¡t sinh viÃªn cá»§a trÆ°á»ng.
                """)

        st.divider()
        
        # Lá»±a chá»n AI model
        st.markdown("### ğŸ¤– Cáº¥u hÃ¬nh AI")
        llm_option = st.selectbox(
            "Chá»n mÃ´ hÃ¬nh AI:", 
            ["Gemini", "Grok"],
            help="Gemini: PhÃ¹ há»£p cho cÃ¢u há»i chung\nGrok: PhÃ¹ há»£p cho phÃ¢n tÃ­ch chi tiáº¿t"
        )
        
        st.divider()
        
        # Thá»‘ng kÃª chat
        st.markdown("### ğŸ“ˆ Thá»‘ng kÃª phiÃªn lÃ m viá»‡c")
        if 'messages' in st.session_state and st.session_state.messages:
            total_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">ğŸ’¬ {total_messages}</div>
                <div class="metric-label">CÃ¢u há»i Ä‘Ã£ há»i</div>
            </div>
            """, unsafe_allow_html=True)
            
            # PhÃ¢n tÃ­ch theo danh má»¥c
            if hasattr(st.session_state, 'chat_logs') and st.session_state.chat_logs:
                categories = {}
                for log in st.session_state.chat_logs:
                    cat = log['category']
                    categories[cat] = categories.get(cat, 0) + 1
                
                st.markdown("**ğŸ“Š PhÃ¢n loáº¡i cÃ¢u há»i:**")
                for cat, count in categories.items():
                    st.markdown(f"â€¢ {cat}: {count} cÃ¢u")
        else:
            st.markdown("""
            <div class="info-card">
                <p>ChÆ°a cÃ³ cÃ¢u há»i nÃ o trong phiÃªn nÃ y.</p>
            </div>
            """, unsafe_allow_html=True)
        
        st.divider()
        
        # ThÃ´ng tin liÃªn há»‡
        st.markdown("### ğŸ“ ThÃ´ng tin liÃªn há»‡")
        st.markdown("""
        <div class="info-card">
            <strong>ğŸ›ï¸ Äáº¡i há»c Luáº­t TPHCM</strong><br>
            ğŸ“ 2 Nguyá»…n Táº¥t ThÃ nh, Q.4, TPHCM<br>
            ğŸ“ Tuyá»ƒn sinh: 1900 5555 14 hoáº·c 0879 5555 14<br>
            ğŸ“ CTSV: (028) 39400 989<br>
            ğŸ“§ tuyensinh@hcmulaw.edu.vn<br>
            ğŸŒ www.hcmulaw.edu.vn
        </div>
        """, unsafe_allow_html=True)

    # Khá»Ÿi táº¡o session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # Kiá»ƒm tra API keys
    if llm_option == "Gemini" and not gemini_api_key:
        st.error("âš ï¸ Vui lÃ²ng cung cáº¥p GEMINI_API_KEY trong file .env")
        st.stop()
    elif llm_option == "Grok" and not grok_api_key:
        st.error("âš ï¸ Vui lÃ²ng cung cáº¥p GROK_API_KEY trong file .env")
        st.stop()

    # Khá»Ÿi táº¡o LLM
    if llm_option == "Gemini":
        llm = get_gemini_llm()
    else:
        llm = get_grok_llm()

    # Khá»Ÿi táº¡o chain náº¿u cÃ³ vector store
    chain = None
    if st.session_state.get('vector_store'):
        chain = create_conversational_chain(st.session_state.vector_store, llm)

    # Ná»™i dung chÃ­nh
    if not st.session_state.messages:
        # Trang chÃ o má»«ng
        st.markdown("### ğŸ‘‹ ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i Chatbot TÆ° Váº¥n!")
        
        # Hiá»ƒn thá»‹ tÃ­nh nÄƒng
        display_features()
        
        # CÃ¢u há»i gá»£i Ã½
        display_quick_questions()
        
        # HÆ°á»›ng dáº«n sá»­ dá»¥ng
        st.markdown("""
        <div class="info-card">
            <h4>ğŸ’¡ CÃ¡ch sá»­ dá»¥ng hiá»‡u quáº£:</h4>
            <ul>
                <li>ğŸ¯ Äáº·t cÃ¢u há»i cá»¥ thá»ƒ vá» lÄ©nh vá»±c báº¡n quan tÃ¢m</li>
                <li>ğŸ“ Cung cáº¥p thÃ´ng tin chi tiáº¿t Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chÃ­nh xÃ¡c</li>
                <li>ğŸ”„ Tiáº¿p tá»¥c há»i Ä‘á»ƒ lÃ m rÃµ thÃªm thÃ´ng tin</li>
                <li>ğŸ“ LiÃªn há»‡ trá»±c tiáº¿p náº¿u cáº§n há»— trá»£ kháº©n cáº¥p</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat vá»›i style má»›i
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant" and "category" in message:
                # Hiá»ƒn thá»‹ badge danh má»¥c
                st.markdown(get_category_badge(message["category"]), unsafe_allow_html=True)
            st.markdown(message["content"])

    # Xá»­ lÃ½ cÃ¢u há»i gá»£i Ã½
    if hasattr(st.session_state, 'suggested_question'):
        prompt = st.session_state.suggested_question
        del st.session_state.suggested_question
    else:
        prompt = st.chat_input("ğŸ’¬ HÃ£y Ä‘áº·t cÃ¢u há»i cá»§a báº¡n...")

    # Xá»­ lÃ½ cÃ¢u há»i
    if prompt:
        # Hiá»ƒn thá»‹ cÃ¢u há»i ngÆ°á»i dÃ¹ng
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # PhÃ¢n loáº¡i cÃ¢u há»i
        question_category = classify_question(prompt)

        # Xá»­ lÃ½ vÃ  tráº£ lá»i
        with st.chat_message("assistant"):
            # Hiá»ƒn thá»‹ badge danh má»¥c
            st.markdown(get_category_badge(question_category), unsafe_allow_html=True)
            
            with st.spinner("ğŸ¤” Äang phÃ¢n tÃ­ch vÃ  tÃ¬m kiáº¿m thÃ´ng tin..."):
                try:
                    if chain and st.session_state.get('vector_store'):
                        # Sá»­ dá»¥ng RAG vá»›i tÃ i liá»‡u
                        response = chain({"question": prompt})
                        answer = response["answer"]
                        
                        # Hiá»ƒn thá»‹ nguá»“n tham kháº£o
                        if response.get("source_documents"):
                            st.markdown("---")
                            with st.expander("ğŸ“š Nguá»“n tham kháº£o tá»« tÃ i liá»‡u", expanded=False):
                                for i, doc in enumerate(response["source_documents"][:3]):
                                    st.markdown(f"""
                                    **ğŸ“„ Nguá»“n {i+1}:** `{doc.metadata.get('source_file', 'N/A')}`
                                    
                                    *Ná»™i dung:* {doc.page_content[:300]}...
                                    """)
                    else:
                        # Sá»­ dá»¥ng AI thuáº§n tÃºy
                        answer = answer_from_external_api(prompt, llm, question_category)
                    
                    st.markdown(answer)
                    
                    # LÆ°u lá»‹ch sá»­
                    save_chat_history(prompt, answer, question_category)
                    
                except Exception as e:
                    error_msg = f"""
                    ğŸ”§ **Xin lá»—i, há»‡ thá»‘ng gáº·p sá»± cá»‘ ká»¹ thuáº­t**
                    
                    Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ trá»±c tiáº¿p:
                    ğŸ“ **Hotline tÆ° váº¥n:** (028) 3838 5052
                    ğŸ“§ **Email:** tuyensinh@hcmulaw.edu.vn
                    
                    *MÃ£ lá»—i: {str(e)}*
                    """
                    st.error(error_msg)
                    answer = error_msg

        # LÆ°u tin nháº¯n vá»›i danh má»¥c
        st.session_state.messages.append({
            "role": "assistant", 
            "content": answer,
            "category": question_category
        })

    # Footer chuyÃªn nghiá»‡p
    st.markdown("---")
    st.markdown("""
    <div class="footer">
        <div class="footer-grid">
            <div class="footer-section">
                <h4>ğŸ›ï¸ TrÆ°á»ng Äáº¡i há»c Luáº­t TPHCM</h4>
                <p>ğŸ“ 2 Nguyá»…n Táº¥t ThÃ nh, PhÆ°á»ng 12, Quáº­n 4, TP.HCM</p>
                <p>ğŸ“ Äiá»‡n thoáº¡i: (028) 39400 989</p>
                <p>ğŸ“§ Email: info@hcmulaw.edu.vn</p>
            </div>
            <div class="footer-section">
                <h4>ğŸ“ Hotline tÆ° váº¥n</h4>
                <p>ğŸ“ Tuyá»ƒn sinh: (028) 39400 989</p>
                <p>ğŸ‘¥ CÃ´ng tÃ¡c SV: ((028) 39400 989</p>
                <p>ğŸ  KÃ½ tÃºc xÃ¡: (028) 39400 989</p>
                <p>ğŸ’° Há»c phÃ­: (028) 39400 989</p>
            </div>
            <div class="footer-section">
                <h4>ğŸŒ LiÃªn káº¿t</h4>
                <p>ğŸŒ Website: www.hcmulaw.edu.vn</p>
                <p>ğŸ“˜ Facebook: /hcmulaw</p>
                <p>ğŸ“º YouTube: /hcmulaw</p>
                <p>ğŸ“§ Zalo: 09123456789</p>
            </div>
        </div>
        <div style="text-align: center; margin-top: 1rem; padding-top: 1rem; border-top: 1px solid rgba(255,255,255,0.2);">
            <p>ğŸ¤– <strong>Chatbot TÆ° Váº¥n</strong> - PhiÃªn báº£n 2.0 | ğŸ•’ Há»— trá»£ 24/7 | ğŸ’¬ Pháº£n há»“i tá»©c thÃ¬</p>
            <p style="font-size: 0.8em; opacity: 0.8;">ÄÆ°á»£c phÃ¡t triá»ƒn bá»Ÿi Lvphung - CNTT - Äáº¡i há»c Luáº­t TPHCM</p>
        </div>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
