import streamlit as st
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain_google_genai import GoogleGenerativeAI
from langchain_openai import OpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
import os
import pickle
import json
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.oauth2.service_account import Credentials
import pandas as pd
from datetime import datetime
import re
import gdown
import requests
from io import BytesIO
import tempfile
import glob
from pathlib import Path
from dotenv import load_dotenv
import base64

def get_base64_of_image(path):
    """Convert image to base64 string"""
    try:
        with open(path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except FileNotFoundError:
        st.error(f"Kh√¥ng t√¨m th·∫•y file logo: {path}")
        return ""
    except Exception as e:
        st.error(f"L·ªói ƒë·ªçc file logo: {e}")
        return ""



# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Chatbot T∆∞ V·∫•n - ƒê·∫°i h·ªçc Lu·∫≠t TPHCM",
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh n√¢ng cao
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    * {
        font-family: 'Inter', sans-serif;
    }
    
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 50%, #1e3c72 100%);
        padding: 2rem;
        border-radius: 20px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(30, 60, 114, 0.3);
        position: relative;
        overflow: hidden;
    }
    .header-logo {
        width: 500px;
        height: 500px;
        margin-bottom: 1rem;
        border-radius: 50%;
        box-shadow: 0 5px 15px rgba(255,255,255,0.2);
        position: relative;
        z-index: 2;
    }
    
    .header-title {
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 1rem;
        margin-bottom: 1rem;
    }
    
    .header-title img {
        width: 60px;
        height: 60px;
        border-radius: 50%;
        box-shadow: 0 3px 10px rgba(255,255,255,0.3);
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
        animation: shimmer 3s infinite;
    }
    
    @keyframes shimmer {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    
    .main-header h1 {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        position: relative;
        z-index: 1;
    }
    
    .main-header h3 {
        font-size: 1.3rem;
        font-weight: 500;
        margin-bottom: 0.5rem;
        opacity: 0.9;
        position: relative;
        z-index: 1;
    }
    
    .main-header p {
        font-size: 1rem;
        opacity: 0.8;
        position: relative;
        z-index: 1;
    }
    
    .chat-message {
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1.5rem 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        backdrop-filter: blur(10px);
        transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    
    .chat-message:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    
    .user-message {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 5px solid #2196f3;
        color: #1565c0;
    }
    
    .assistant-message {
        background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
        border-left: 5px solid #9c27b0;
        color: #6a1b9a;
    }
    
    .sidebar-info {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
    }
    
    .file-status {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #4caf50;
        box-shadow: 0 2px 8px rgba(76, 175, 80, 0.2);
    }
    
    .metric-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        border: 1px solid #e9ecef;
        margin: 0.5rem 0;
        transition: transform 0.2s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.15);
    }
    
    .metric-value {
        font-size: 2rem;
        font-weight: 700;
        color: #1e3c72;
        margin-bottom: 0.5rem;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #6c757d;
        font-weight: 500;
    }
    
    .info-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
        border: 1px solid #ffb74d;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(255, 183, 77, 0.2);
    }
    
    .success-card {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        border: 1px solid #4caf50;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(76, 175, 80, 0.2);
    }
    
    .warning-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffcc80 100%);
        border: 1px solid #ff9800;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(255, 152, 0, 0.2);
    }
    
    .category-badge {
        display: inline-block;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 600;
        margin: 0.2rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    .badge-tuyensinh {
        background: linear-gradient(135deg, #e3f2fd 0%, #90caf9 100%);
        color: #1565c0;
    }
    
    .badge-hocphi {
        background: linear-gradient(135deg, #e8f5e8 0%, #a5d6a7 100%);
        color: #2e7d32;
    }
    
    .badge-chuongtrinh {
        background: linear-gradient(135deg, #f3e5f5 0%, #ce93d8 100%);
        color: #6a1b9a;
    }
    
    .badge-sinhhoat {
        background: linear-gradient(135deg, #fff3e0 0%, #ffcc80 100%);
        color: #e65100;
    }
    
    .badge-hotro {
        background: linear-gradient(135deg, #fce4ec 0%, #f8bbd9 100%);
        color: #c2185b;
    }
    
    .badge-totnghiep {
        background: linear-gradient(135deg, #e0f2f1 0%, #80cbc4 100%);
        color: #00695c;
    }
    
    .quick-actions {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 1rem;
        margin: 1.5rem 0;
    }
    
    .action-button {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border: 2px solid #e9ecef;
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        cursor: pointer;
        transition: all 0.3s ease;
        text-decoration: none;
        color: #495057;
    }
    
    .action-button:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 25px rgba(0,0,0,0.15);
        border-color: #2196f3;
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
    }
    
    .action-icon {
        font-size: 2rem;
        margin-bottom: 0.5rem;
        display: block;
    }
    
    .footer {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-top: 3rem;
        text-align: center;
    }
    
    .footer-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
        gap: 2rem;
        margin-bottom: 1rem;
    }
    
    .footer-section h4 {
        color: #90caf9;
        margin-bottom: 1rem;
        font-weight: 600;
    }
    
    .footer-section p {
        margin-bottom: 0.5rem;
        opacity: 0.9;
    }
    
    .stSelectbox > div > div {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border-radius: 10px;
        border: 2px solid #e9ecef;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #2196f3 0%, #1976d2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #1976d2 0%, #1565c0 100%);
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(33, 150, 243, 0.3);
    }
    
    .chat-input {
        border-radius: 25px !important;
        border: 2px solid #e9ecef !important;
        padding: 1rem 1.5rem !important;
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%) !important;
    }
    
    .stChatInput > div > div > textarea {
        border-radius: 25px;
        border: 2px solid #e9ecef;
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
    }
    
    .loading-container {
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 2rem;
    }
    
    .loading-spinner {
        width: 40px;
        height: 40px;
        border: 4px solid #e9ecef;
        border-top: 4px solid #2196f3;
        border-radius: 50%;
        animation: spin 1s linear infinite;
    }
    
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 1.5rem;
        margin: 2rem 0;
    }
    
    .feature-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border: 1px solid #e9ecef;
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 25px rgba(0,0,0,0.15);
    }
    
    .feature-icon {
        font-size: 3rem;
        margin-bottom: 1rem;
        color: #2196f3;
    }
    
    .feature-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #1e3c72;
        margin-bottom: 0.5rem;
    }
    
    .feature-description {
        color: #6c757d;
        font-size: 0.9rem;
        line-height: 1.5;
    }
    data-testid="stToolbarActionButtonIcon"],[data-testid="stToolbarActionButtonLabel"] {
    display: none !important;
}
[data-testid="stToolbar"] button:has([data-testid="stToolbarActionButtonIcon"]),
[data-testid="stToolbar"] button:has([data-testid="stToolbarActionButtonLabel"])
{
    pointer-events: none !important;
}
}
[data-testid="stToolbarActionButtonLabel"] {
        display: none !important;
    }
[data-testid="stAlert"] {
    display: none !important;
}  
</style>
""", unsafe_allow_html=True)

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()
grok_api_key = os.getenv("GROK_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")

GDRIVE_VECTORSTORE_ID = os.getenv("GDRIVE_VECTORSTORE_ID")  # ID file pkl tr√™n GDrive
GDRIVE_METADATA_ID = os.getenv("GDRIVE_METADATA_ID")        # ID file metadata tr√™n GDrive
GDRIVE_FOLDER_ID = os.getenv("GDRIVE_FOLDER_ID")            # ID folder ch·ª©a vectorstore
# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n
DOCUMENTS_PATH = "documents"
VECTORSTORE_PATH = "vectorstore"
CACHE_PATH = "cache"

# T·∫°o c√°c th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
for path in [DOCUMENTS_PATH, VECTORSTORE_PATH, CACHE_PATH]:
    Path(path).mkdir(exist_ok=True)

# Template prompt chuy√™n bi·ªát cho t∆∞ v·∫•n tuy·ªÉn sinh
COUNSELING_PROMPT_TEMPLATE = """
B·∫°n l√† chuy√™n gia t∆∞ v·∫•n tuy·ªÉn sinh Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh.
H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p v√† ki·∫øn th·ª©c chuy√™n m√¥n.

TH√îNG TIN LI√äN H·ªÜ CH√çNH TH·ª®C:
- Ph√≤ng Tuy·ªÉn sinh: 1900 5555 14 ho·∫∑c 0879 5555 14
- Email tuy·ªÉn sinh: tuyensinh@hcmulaw.edu.vn
- Email chung: ict@hcmulaw.edu.vn
- ƒêi·ªán tho·∫°i: (028) 39400 989
- ƒê·ªãa ch·ªâ: 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM
- Website: www.hcmulaw.edu.vn
- Facebook: facebook.com/hcmulaw
- Zalo OA: ƒê·∫°i h·ªçc Lu·∫≠t TPHCM

TH√îNG TIN C∆† B·∫¢N V·ªÄ TR∆Ø·ªúNG:
- T√™n ƒë·∫ßy ƒë·ªß: Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh
- M√£ tr∆∞·ªùng: LHP
- Lo·∫°i h√¨nh: ƒê·∫°i h·ªçc c√¥ng l·∫≠p
- Th√†nh l·∫≠p: 1996
- ƒê√†o t·∫°o: ƒê·∫°i h·ªçc, Th·∫°c sƒ©, Ti·∫øn sƒ©


H·ªåC PH√ç THAM KH·∫¢O (C·∫≠p nh·∫≠t theo nƒÉm h·ªçc):

Nguy√™n t·∫Øc tr·∫£ l·ªùi:
1. Th√¢n thi·ªán, chuy√™n nghi·ªáp v√† d·ªÖ hi·ªÉu
2. Cung c·∫•p th√¥ng tin ch√≠nh x√°c, c·ª• th·ªÉ v·ªÅ ƒê·∫°i h·ªçc Lu·∫≠t TPHCM
3. ƒê∆∞a ra l·ªùi khuy√™n ph√π h·ª£p v·ªõi t·ª´ng tr∆∞·ªùng h·ª£p
4. H∆∞·ªõng d·∫´n c√°c b∆∞·ªõc c·∫ßn thi·∫øt n·∫øu c√≥
5. Lu√¥n khuy·∫øn kh√≠ch v√† t·∫°o ƒë·ªông l·ª±c t√≠ch c·ª±c
6. Cung c·∫•p th√¥ng tin li√™n h·ªá C·ª§ TH·ªÇ khi c·∫ßn thi·∫øt (kh√¥ng ƒë∆∞·ª£c d√πng placeholder)
7. N·∫øu kh√¥ng c√≥ th√¥ng tin ch√≠nh x√°c, h√£y n√≥i r√µ v√† khuy·∫øn kh√≠ch li√™n h·ªá tr·ª±c ti·∫øp

Th√¥ng tin tham kh·∫£o: {context}

L·ªãch s·ª≠ h·ªôi tho·∫°i: {chat_history}

C√¢u h·ªèi c·ªßa sinh vi√™n/th√≠ sinh: {question}

Tr·∫£ l·ªùi (b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán v√† chuy√™n nghi·ªáp):
"""

# H√†m tr·∫£ l·ªùi t·ª´ API b√™n ngo√†i - PHI√äN B·∫¢N C·∫¨P NH·∫¨T
def answer_from_external_api(prompt, llm, question_category):
    enhanced_prompt = f"""
    B·∫°n l√† chuy√™n gia t∆∞ v·∫•n {question_category.lower()} c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh.
    
    TH√îNG TIN LI√äN H·ªÜ CH√çNH TH·ª®C (LU√îN S·ª¨ D·ª§NG TH√îNG TIN N√ÄY):
    - Ph√≤ng Tuy·ªÉn sinh: 1900 5555 14 ho·∫∑c 0879 5555 14
    - Email tuy·ªÉn sinh: tuyensinh@hcmulaw.edu.vn
    - Email chung: ict@hcmulaw.edu.vn
    - ƒêi·ªán tho·∫°i: (028) 39400 989
    - ƒê·ªãa ch·ªâ: 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM
    - Website: www.hcmulaw.edu.vn
    - Facebook: facebook.com/hcmulaw
    
    TH√îNG TIN C∆† B·∫¢N:
    - ƒê·∫°i h·ªçc Lu·∫≠t TPHCM th√†nh l·∫≠p nƒÉm 1996
    - M√£ tr∆∞·ªùng: LHP
    - Lo·∫°i h√¨nh: ƒê·∫°i h·ªçc c√¥ng l·∫≠p
    - ƒê√†o t·∫°o: ƒê·∫°i h·ªçc,  Th·∫°c sƒ©, Ti·∫øn sƒ©
    
    
    C√¢u h·ªèi: {prompt}
    
    QUY T·∫ÆC QUAN TR·ªåNG:
    - KH√îNG ƒë∆∞·ª£c s·ª≠ d·ª•ng placeholder nh∆∞ [S·ªë ƒëi·ªán tho·∫°i], [Email] 
    - PH·∫¢I s·ª≠ d·ª•ng th√¥ng tin li√™n h·ªá c·ª• th·ªÉ ·ªü tr√™n
    - N·∫øu kh√¥ng c√≥ th√¥ng tin ch√≠nh x√°c v·ªÅ m·ªôt v·∫•n ƒë·ªÅ c·ª• th·ªÉ, h√£y n√≥i r√µ v√† khuy·∫øn kh√≠ch li√™n h·ªá
    - Lu√¥n k·∫øt th√∫c b·∫±ng th√¥ng tin li√™n h·ªá c·ª• th·ªÉ
    
    H√£y tr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán, chuy√™n nghi·ªáp v√† h·ªØu √≠ch v·ªõi th√¥ng tin c·ª• th·ªÉ.
    """
    
    try:
        if isinstance(llm, GoogleGenerativeAI):
            response = llm.invoke(enhanced_prompt)
        else:
            response = llm.invoke(enhanced_prompt)
        
        # Ki·ªÉm tra v√† thay th·∫ø c√°c placeholder c√≤n s√≥t l·∫°i
        response = response.replace("[S·ªë ƒëi·ªán tho·∫°i ph√≤ng Tuy·ªÉn sinh - c·∫ßn c·∫≠p nh·∫≠t th√¥ng tin ch√≠nh th·ª©c t·ª´ tr∆∞·ªùng]", "1900 5555 14 ho·∫∑c 0879 5555 14")
        response = response.replace("[Email ph√≤ng Tuy·ªÉn sinh - c·∫ßn c·∫≠p nh·∫≠t th√¥ng tin ch√≠nh th·ª©c t·ª´ tr∆∞·ªùng]", "tuyensinh@hcmulaw.edu.vn")
        response = response.replace("[Website tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t TPHCM - c·∫ßn c·∫≠p nh·∫≠t th√¥ng tin ch√≠nh th·ª©c t·ª´ tr∆∞·ªùng]", "www.hcmulaw.edu.vn")
        response = response.replace("[Email]", "ict@hcmulaw.edu.vn")
        response = response.replace("[ƒêi·ªán tho·∫°i]", "(028) 39400 989")
        
        # Th√™m th√¥ng tin li√™n h·ªá c·ª• th·ªÉ n·∫øu ch∆∞a c√≥
        if "li√™n h·ªá" in response.lower() and "1900 5555 14" not in response:
            response += "\n\n**Th√¥ng tin li√™n h·ªá:**\n"
            response += "üìû **Hotline tuy·ªÉn sinh:** 1900 5555 14 ho·∫∑c 0879 5555 14\n"
            response += "üìß **Email:** tuyensinh@hcmulaw.edu.vn\n"
            response += "üåê **Website:** www.hcmulaw.edu.vn\n"
            response += "üìç **ƒê·ªãa ch·ªâ:** 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM"
            
        return response
        
    except Exception as e:
        return f"""
        Xin l·ªói, h·ªá th·ªëng g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng li√™n h·ªá tr·ª±c ti·∫øp:
        
        üìû **Hotline tuy·ªÉn sinh:** 1900 5555 14 ho·∫∑c 0879 5555 14
        üìß **Email:** tuyensinh@hcmulaw.edu.vn
        üåê **Website:** www.hcmulaw.edu.vn
        üìç **ƒê·ªãa ch·ªâ:** 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM
        
        M√£ l·ªói: {str(e)}
        """

# H√†m ki·ªÉm tra v√† l√†m s·∫°ch response t·ª´ placeholder
def clean_response(response_text):
    """L√†m s·∫°ch response, thay th·∫ø placeholder b·∫±ng th√¥ng tin th·ª±c"""
    
    # Dictionary mapping placeholder to actual info
    replacements = {
        "[S·ªë ƒëi·ªán tho·∫°i ph√≤ng Tuy·ªÉn sinh - c·∫ßn c·∫≠p nh·∫≠t th√¥ng tin ch√≠nh th·ª©c t·ª´ tr∆∞·ªùng]": "1900 5555 14 ho·∫∑c 0879 5555 14",
        "[Email ph√≤ng Tuy·ªÉn sinh - c·∫ßn c·∫≠p nh·∫≠t th√¥ng tin ch√≠nh th·ª©c t·ª´ tr∆∞·ªùng]": "tuyensinh@hcmulaw.edu.vn",
        "[Website tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t TPHCM - c·∫ßn c·∫≠p nh·∫≠t th√¥ng tin ch√≠nh th·ª©c t·ª´ tr∆∞·ªùng]": "www.hcmulaw.edu.vn",
        "[Email]": "ict@hcmulaw.edu.vn",
        "[ƒêi·ªán tho·∫°i]": "(028) 39400 989",
        "[ƒê·ªãa ch·ªâ]": "2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM",
        "[Hotline]": "1900 5555 14 ho·∫∑c 0879 5555 14",
        "[Facebook]": "facebook.com/hcmulaw"
    }
    
    # Thay th·∫ø t·∫•t c·∫£ placeholder
    for placeholder, actual_info in replacements.items():
        response_text = response_text.replace(placeholder, actual_info)
    
    # Th√™m th√¥ng tin li√™n h·ªá c·ª• th·ªÉ n·∫øu response qu√° chung chung
    if ("li√™n h·ªá" in response_text.lower() or "th√¥ng tin" in response_text.lower()) and "1900 5555 14" not in response_text:
        response_text += "\n\n**Th√¥ng tin li√™n h·ªá c·ª• th·ªÉ:**\n"
        response_text += "üìû **Hotline tuy·ªÉn sinh:** 1900 5555 14 ho·∫∑c 0879 5555 14\n"
        response_text += "üìß **Email:** tuyensinh@hcmulaw.edu.vn\n"
        response_text += "üåê **Website:** www.hcmulaw.edu.vn\n"
        response_text += "üìç **ƒê·ªãa ch·ªâ:** 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM"
    
    return response_text
def get_drive_service():
    """Kh·ªüi t·∫°o Google Drive service - PHI√äN B·∫¢N C·∫¢I TI·∫æN"""
    try:
        # Th·ª≠ t·ª´ bi·∫øn m√¥i tr∆∞·ªùng tr∆∞·ªõc
        if 'GOOGLE_APPLICATION_CREDENTIALS' in os.environ:
            credentials = Credentials.from_service_account_file(
                os.environ['GOOGLE_APPLICATION_CREDENTIALS'],
                scopes=['https://www.googleapis.com/auth/drive']
            )
        elif os.path.exists('service_account.json'):
            credentials = Credentials.from_service_account_file(
                'service_account.json',
                scopes=['https://www.googleapis.com/auth/drive']
            )
        else:
            # Th·ª≠ t·ª´ service account info trong env
            service_account_info = os.getenv('GOOGLE_SERVICE_ACCOUNT_JSON')
            if service_account_info:
                import json
                service_account_dict = json.loads(service_account_info)
                credentials = Credentials.from_service_account_info(
                    service_account_dict,
                    scopes=['https://www.googleapis.com/auth/drive']
                )
            else:
                raise Exception("Kh√¥ng t√¨m th·∫•y th√¥ng tin service account")
        
        service = build('drive', 'v3', credentials=credentials)
        
        # Test connection
        service.files().list(pageSize=1).execute()
        print("‚úÖ K·∫øt n·ªëi Google Drive th√†nh c√¥ng")
        return service
        
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o Drive service: {e}")
        return None

def upload_to_gdrive(file_path, file_id=None, folder_id=None):
    """Upload file l√™n Google Drive - PHI√äN B·∫¢N C·∫¢I TI·∫æN"""
    try:
        service = get_drive_service()
        if not service:
            print("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o Google Drive service")
            return False
        
        file_name = os.path.basename(file_path)
        
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(file_path):
            print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {file_path}")
            return False
            
        # Media upload v·ªõi resumable
        media = MediaFileUpload(
            file_path, 
            resumable=True,
            chunksize=1024*1024  # 1MB chunks
        )
        
        if file_id:
            # C·∫≠p nh·∫≠t file hi·ªán c√≥
            try:
                file_metadata = {'name': file_name}
                updated_file = service.files().update(
                    fileId=file_id,
                    body=file_metadata,
                    media_body=media
                ).execute()
                print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t file {file_name} (ID: {updated_file.get('id')})")
                return True
            except Exception as e:
                print(f"‚ùå L·ªói c·∫≠p nh·∫≠t file: {e}")
                return False
        else:
            # T·∫°o file m·ªõi
            try:
                file_metadata = {
                    'name': file_name,
                    'parents': [folder_id] if folder_id else []
                }
                created_file = service.files().create(
                    body=file_metadata,
                    media_body=media,
                    fields='id,name,size'
                ).execute()
                print(f"‚úÖ ƒê√£ t·∫°o file m·ªõi {file_name} (ID: {created_file.get('id')})")
                return created_file.get('id')
            except Exception as e:
                print(f"‚ùå L·ªói t·∫°o file m·ªõi: {e}")
                return False
                
    except Exception as e:
        print(f"‚ùå L·ªói upload l√™n Google Drive: {e}")
        return False

ef save_vectorstore_cache(vectorstore, metadata):
    """L∆∞u vector store l√™n Google Drive - PHI√äN B·∫¢N C·∫¢I TI·∫æN"""
    try:
        # T·∫°o th∆∞ m·ª•c t·∫°m v·ªõi t√™n unique
        temp_dir = tempfile.mkdtemp(prefix='chatbot_')
        vectorstore_path = os.path.join(temp_dir, "vectorstore.pkl")
        metadata_path = os.path.join(temp_dir, "metadata.json")
        
        print("üîÑ ƒêang chu·∫©n b·ªã l∆∞u vectorstore...")
        
        # L∆∞u vectorstore v·ªõi compression
        with open(vectorstore_path, 'wb') as f:
            pickle.dump(vectorstore, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        # Ki·ªÉm tra k√≠ch th∆∞·ªõc file
        vectorstore_size = os.path.getsize(vectorstore_path)
        print(f"üì¶ Vectorstore size: {vectorstore_size / (1024*1024):.2f} MB")
        
        # L∆∞u metadata
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        metadata_size = os.path.getsize(metadata_path)
        print(f"üìÑ Metadata size: {metadata_size / 1024:.2f} KB")
        
        # Upload v·ªõi retry logic
        success_vectorstore = False
        success_metadata = False
        
        for attempt in range(3):  # Retry 3 l·∫ßn
            if not success_vectorstore:
                print(f"‚¨ÜÔ∏è ƒêang upload vectorstore (l·∫ßn {attempt + 1}/3)...")
                result = upload_to_gdrive(
                    vectorstore_path, 
                    GDRIVE_VECTORSTORE_ID,
                    GDRIVE_FOLDER_ID
                )
                success_vectorstore = bool(result)
                
            if not success_metadata:
                print(f"‚¨ÜÔ∏è ƒêang upload metadata (l·∫ßn {attempt + 1}/3)...")
                result = upload_to_gdrive(
                    metadata_path, 
                    GDRIVE_METADATA_ID,
                    GDRIVE_FOLDER_ID
                )
                success_metadata = bool(result)
                
            if success_vectorstore and success_metadata:
                break
                
            if attempt < 2:  # Kh√¥ng sleep ·ªü l·∫ßn cu·ªëi
                print(f"‚è≥ Ch·ªù {2 ** attempt} gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i...")
                time.sleep(2 ** attempt)
        
        # D·ªçn d·∫πp file t·∫°m
        try:
            os.remove(vectorstore_path)
            os.remove(metadata_path)
            os.rmdir(temp_dir)
        except Exception as cleanup_error:
            print(f"‚ö†Ô∏è L·ªói d·ªçn d·∫πp file t·∫°m: {cleanup_error}")
        
        if success_vectorstore and success_metadata:
            print("‚úÖ ƒê√£ l∆∞u vectorstore l√™n Google Drive th√†nh c√¥ng!")
            return True
        else:
            print("‚ùå C√≥ l·ªói khi upload l√™n Google Drive")
            print(f"   - Vectorstore: {'‚úÖ' if success_vectorstore else '‚ùå'}")
            print(f"   - Metadata: {'‚úÖ' if success_metadata else '‚ùå'}")
            return False
            
    except Exception as e:
        print(f"‚ùå L·ªói l∆∞u vectorstore: {e}")
        return False
def download_from_gdrive(file_id, output_path):
    """Download file t·ª´ Google Drive - PHI√äN B·∫¢N C·∫¢I TI·∫æN"""
    try:
        # Th·ª≠ d√πng gdown tr∆∞·ªõc
        url = f'https://drive.google.com/uc?id={file_id}'
        gdown.download(url, output_path, quiet=True)
        
        # Ki·ªÉm tra file ƒë√£ download th√†nh c√¥ng
        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            return True
        else:
            raise Exception("File download r·ªóng ho·∫∑c kh√¥ng t·ªìn t·∫°i")
            
    except Exception as e:
        print(f"‚ùå L·ªói download t·ª´ gdown, th·ª≠ d√πng Drive API: {e}")
        
        # Fallback: s·ª≠ d·ª•ng Drive API
        try:
            service = get_drive_service()
            if not service:
                return False
                
            request = service.files().get_media(fileId=file_id)
            with open(output_path, 'wb') as f:
                downloader = MediaIoBaseDownload(f, request)
                done = False
                while done is False:
                    status, done = downloader.next_chunk()
            return True
            
        except Exception as e2:
            print(f"‚ùå L·ªói download t·ª´ Drive API: {e2}")
            return False

def save_vectorstore_cache(vectorstore, metadata):
    """L∆∞u vector store l√™n Google Drive - PHI√äN B·∫¢N C·∫¨P NH·∫¨T"""
    try:
        # T·∫°o th∆∞ m·ª•c t·∫°m
        temp_dir = tempfile.mkdtemp()
        vectorstore_path = os.path.join(temp_dir, "vectorstore.pkl")
        metadata_path = os.path.join(temp_dir, "metadata.json")
        
        print("üîÑ ƒêang chu·∫©n b·ªã l∆∞u vectorstore...")
        
        # L∆∞u vectorstore v√†o file t·∫°m
        with open(vectorstore_path, 'wb') as f:
            pickle.dump(vectorstore, f)
        print(f"üì¶ ƒê√£ t·∫°o vectorstore.pkl ({os.path.getsize(vectorstore_path)} bytes)")
        
        # L∆∞u metadata v√†o file t·∫°m
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"üìÑ ƒê√£ t·∫°o metadata.json ({os.path.getsize(metadata_path)} bytes)")
        
        # Upload l√™n Google Drive
        print("‚¨ÜÔ∏è ƒêang upload l√™n Google Drive...")
        success_vectorstore = upload_to_gdrive(vectorstore_path, 
                                             globals().get('GDRIVE_VECTORSTORE_ID'))
        success_metadata = upload_to_gdrive(metadata_path, 
                                          globals().get('GDRIVE_METADATA_ID'))
        
        # D·ªçn d·∫πp file t·∫°m
        os.remove(vectorstore_path)
        os.remove(metadata_path)
        os.rmdir(temp_dir)
        
        if success_vectorstore and success_metadata:
            print("‚úÖ ƒê√£ l∆∞u vectorstore l√™n Google Drive th√†nh c√¥ng!")
            return True
        else:
            print("‚ùå C√≥ l·ªói khi upload l√™n Google Drive")
            return False
            
    except Exception as e:
        print(f"‚ùå L·ªói l∆∞u vectorstore: {e}")
        # D·ªçn d·∫πp n·∫øu c√≥ l·ªói
        try:
            if os.path.exists(vectorstore_path):
                os.remove(vectorstore_path)
            if os.path.exists(metadata_path):
                os.remove(metadata_path)
            if os.path.exists(temp_dir):
                os.rmdir(temp_dir)
        except:
            pass
        return False

# H√†m ki·ªÉm tra k√≠ch th∆∞·ªõc file tr√™n Google Drive
def check_gdrive_file_size(file_id):
    """Ki·ªÉm tra k√≠ch th∆∞·ªõc file tr√™n Google Drive"""
    try:
        service = get_drive_service()
        if not service:
            return None
            
        file_info = service.files().get(fileId=file_id, fields='size,name,modifiedTime').execute()
        return {
            'name': file_info.get('name'),
            'size': int(file_info.get('size', 0)),
            'modified_time': file_info.get('modifiedTime')
        }
    except Exception as e:
        print(f"‚ùå L·ªói ki·ªÉm tra file info: {e}")
        return None

# H√†m debug ƒë·ªÉ ki·ªÉm tra tr·∫°ng th√°i
def debug_vectorstore_status():
    """Debug tr·∫°ng th√°i vector store"""
    print("üîç DEBUG: Ki·ªÉm tra tr·∫°ng th√°i vector store...")
    
    # Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng
    vectorstore_id = globals().get('GDRIVE_VECTORSTORE_ID')
    metadata_id = globals().get('GDRIVE_METADATA_ID')
    
    print(f"üìç GDRIVE_VECTORSTORE_ID: {vectorstore_id}")
    print(f"üìç GDRIVE_METADATA_ID: {metadata_id}")
    
    if vectorstore_id:
        info = check_gdrive_file_size(vectorstore_id)
        if info:
            print(f"üì¶ Vectorstore: {info['name']} - {info['size']} bytes - {info['modified_time']}")
    
    if metadata_id:
        info = check_gdrive_file_size(metadata_id)
        if info:
            print(f"üìÑ Metadata: {info['name']} - {info['size']} bytes - {info['modified_time']}")

# Kh·ªüi t·∫°o embeddings v·ªõi model ph√π h·ª£p ti·∫øng Vi·ªát
@st.cache_resource
def load_embeddings():
    return HuggingFaceEmbeddings(
        model_name="keepitreal/vietnamese-sbert",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

embeddings = load_embeddings()

# H√†m l·∫•y danh s√°ch file t·ª´ th∆∞ m·ª•c documents
def get_document_files():
    """L·∫•y danh s√°ch t·∫•t c·∫£ file trong th∆∞ m·ª•c documents"""
    supported_extensions = ['*.pdf', '*.docx', '*.txt']
    files = []
    
    for ext in supported_extensions:
        files.extend(glob.glob(os.path.join(DOCUMENTS_PATH, '**', ext), recursive=True))
    
    return files

# H√†m t·∫°o hash cho file ƒë·ªÉ ki·ªÉm tra thay ƒë·ªïi
def get_file_hash(file_path):
    """T·∫°o hash cho file ƒë·ªÉ ki·ªÉm tra thay ƒë·ªïi"""
    stat = os.stat(file_path)
    return f"{stat.st_mtime}_{stat.st_size}"

# H√†m ki·ªÉm tra cache vector store
def load_cached_vectorstore():
    """Load vector store t·ª´ Google Drive"""
    
    # T·∫°o th∆∞ m·ª•c t·∫°m
    temp_dir = tempfile.mkdtemp()
    vectorstore_path = os.path.join(temp_dir, "vectorstore.pkl")
    metadata_path = os.path.join(temp_dir, "metadata.json")
    
    try:
        # Download vectorstore t·ª´ Google Drive
        if GDRIVE_VECTORSTORE_ID:
            if not download_from_gdrive(GDRIVE_VECTORSTORE_ID, vectorstore_path):
                return None, {}
        else:
            #st.warning("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh GDRIVE_VECTORSTORE_ID")
            return None, {}
        
        # Download metadata t·ª´ Google Drive
        if GDRIVE_METADATA_ID:
            if not download_from_gdrive(GDRIVE_METADATA_ID, metadata_path):
                return None, {}
        else:
            #st.warning("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh GDRIVE_METADATA_ID")
            return None, {}
        
        # Load vectorstore
        with open(vectorstore_path, 'rb') as f:
            vectorstore = pickle.load(f)
        
        # Load metadata
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # D·ªçn d·∫πp file t·∫°m
        os.remove(vectorstore_path)
        os.remove(metadata_path)
        os.rmdir(temp_dir)
        
        return vectorstore, metadata
        
    except Exception as e:
        #st.error(f"L·ªói load vectorstore t·ª´ Google Drive: {e}")
        # D·ªçn d·∫πp file t·∫°m n·∫øu c√≥ l·ªói
        try:
            if os.path.exists(vectorstore_path):
                os.remove(vectorstore_path)
            if os.path.exists(metadata_path):
                os.remove(metadata_path)
            os.rmdir(temp_dir)
        except:
            pass
        return None, {}

# H√†m l∆∞u vector store v√†o cache
def save_vectorstore_cache(vectorstore, metadata):
    """L∆∞u vector store l√™n Google Drive"""
    try:
        # T·∫°o th∆∞ m·ª•c t·∫°m
        temp_dir = tempfile.mkdtemp()
        vectorstore_path = os.path.join(temp_dir, "vectorstore.pkl")
        metadata_path = os.path.join(temp_dir, "metadata.json")
        
        # L∆∞u vectorstore v√†o file t·∫°m
        with open(vectorstore_path, 'wb') as f:
            pickle.dump(vectorstore, f)
        
        # L∆∞u metadata v√†o file t·∫°m
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # Upload l√™n Google Drive
        success_vectorstore = upload_to_gdrive(vectorstore_path, GDRIVE_VECTORSTORE_ID)
        success_metadata = upload_to_gdrive(metadata_path, GDRIVE_METADATA_ID)
        
        # D·ªçn d·∫πp file t·∫°m
        os.remove(vectorstore_path)
        os.remove(metadata_path)
        os.rmdir(temp_dir)
        return True
        
       
            
    except Exception as e:
        #st.error(f"L·ªói l∆∞u vectorstore l√™n Google Drive: {e}")
        return False

# H√†m ki·ªÉm tra xem c√≥ c·∫ßn rebuild vector store kh√¥ng
def need_rebuild_vectorstore():
    """Ki·ªÉm tra xem c√≥ c·∫ßn rebuild vector store kh√¥ng"""
    current_files = get_document_files()
    
    if not current_files:
        return False, {}, []
    
    # T·∫°o metadata hi·ªán t·∫°i
    current_metadata = {}
    for file_path in current_files:
        current_metadata[file_path] = get_file_hash(file_path)
    
    # Load cached metadata t·ª´ Google Drive
    _, cached_metadata = load_cached_vectorstore()
    
    # TH√äM: Ki·ªÉm tra xem c√≥ file m·ªõi hay file b·ªã x√≥a kh√¥ng
    cached_files = set(cached_metadata.get('files', {}).keys())
    current_files_set = set(current_files)
    
    # N·∫øu c√≥ file m·ªõi ho·∫∑c file b·ªã x√≥a, c·∫ßn rebuild
    if cached_files != current_files_set:
        return True, current_metadata, current_files
    
    # So s√°nh hash c·ªßa t·ª´ng file
    if current_metadata != cached_metadata.get('files', {}):
        return True, current_metadata, current_files
    
    return False, current_metadata, current_files
def check_gdrive_connection():
    """Ki·ªÉm tra k·∫øt n·ªëi v√† c·∫•u h√¨nh Google Drive"""
    issues = []
    
    if not GDRIVE_VECTORSTORE_ID:
        issues.append("‚ùå Thi·∫øu GDRIVE_VECTORSTORE_ID")
    
    if not GDRIVE_METADATA_ID:
        issues.append("‚ùå Thi·∫øu GDRIVE_METADATA_ID")
    
    if not GDRIVE_FOLDER_ID:
        issues.append("‚ö†Ô∏è Thi·∫øu GDRIVE_FOLDER_ID (t√πy ch·ªçn)")
    
    return len(issues) == 0, issues

# H√†m x·ª≠ l√Ω file t√†i li·ªáu
def process_documents(file_paths):
    """X·ª≠ l√Ω danh s√°ch file t√†i li·ªáu"""
    documents = []
    processed_files = []
    failed_files = []
    
    for file_path in file_paths:
        try:
            file_extension = Path(file_path).suffix.lower()
            
            if file_extension == ".pdf":
                loader = PyPDFLoader(file_path)
            elif file_extension == ".docx":
                loader = Docx2txtLoader(file_path)
            elif file_extension == ".txt":
                loader = TextLoader(file_path, encoding='utf-8')
            else:
                failed_files.append(f"{file_path} (kh√¥ng h·ªó tr·ª£)")
                continue
            
            docs = loader.load()
            
            # Th√™m metadata
            for doc in docs:
                doc.metadata['source_file'] = os.path.basename(file_path)
                doc.metadata['file_path'] = file_path
                doc.metadata['processed_time'] = datetime.now().isoformat()
            
            documents.extend(docs)
            processed_files.append(file_path)
            
        except Exception as e:
            failed_files.append(f"{file_path} (l·ªói: {str(e)})")
    
    return documents, processed_files, failed_files

# H√†m t·∫°o vector store
def create_vector_store(documents):
    """T·∫°o vector store t·ª´ documents"""
    if not documents:
        return None
        
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=['\n\n', '\n', '.', '!', '?', ';', ':', ' ']
    )
    texts = text_splitter.split_documents(documents)
    
    # L·ªçc b·ªè c√°c chunk qu√° ng·∫Øn
    texts = [text for text in texts if len(text.page_content.strip()) > 50]
    
    if not texts:
        return None
        
    vector_store = FAISS.from_documents(texts, embeddings)
    return vector_store

# H√†m kh·ªüi t·∫°o ho·∫∑c load vector store
@st.cache_resource
def initialize_vectorstore(_force_rebuild=False):
    """Kh·ªüi t·∫°o ho·∫∑c load vector store"""
    # Check force rebuild flag
    if _force_rebuild or st.session_state.get('force_rebuild', False):
        # Clear force rebuild flag
        if 'force_rebuild' in st.session_state:
            del st.session_state.force_rebuild
        # Force rebuild
        need_rebuild = True
        current_files = get_document_files()
        current_metadata = {}
        for file_path in current_files:
            current_metadata[file_path] = get_file_hash(file_path)
    else:
        need_rebuild, current_metadata, current_files = need_rebuild_vectorstore()
    
    if not need_rebuild and not _force_rebuild:
        # Load t·ª´ cache
        vectorstore, cached_metadata = load_cached_vectorstore()
        if vectorstore:
            return vectorstore, cached_metadata.get('files', {}), cached_metadata.get('stats', {})
    
    # Rebuild vector store
    if not current_files:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file n√†o trong th∆∞ m·ª•c documents")
        return None, {}, {}
    
    with st.spinner("üîÑ ƒêang x·ª≠ l√Ω t√†i li·ªáu m·ªõi..."):
        documents, processed_files, failed_files = process_documents(current_files)
        
        if not documents:
            st.error("‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω file n√†o")
            return None, {}, {}
        
        vectorstore = create_vector_store(documents)
        
        if vectorstore:
            # T·∫°o metadata ƒë·ªÉ l∆∞u
            metadata_to_save = {
                'files': current_metadata,
                'stats': {
                    'total_files': len(current_files),
                    'processed_files': len(processed_files),
                    'failed_files': len(failed_files),
                    'total_chunks': vectorstore.index.ntotal,
                    'last_updated': datetime.now().isoformat()
                },
                'processed_files': processed_files,
                'failed_files': failed_files
            }
            
            # L∆∞u cache
            save_success = save_vectorstore_cache(vectorstore, metadata_to_save)
            if save_success:
                st.success("‚úÖ ƒê√£ c·∫≠p nh·∫≠t vectorstore th√†nh c√¥ng!")
            else:
                st.warning("‚ö†Ô∏è Vectorstore ƒë∆∞·ª£c t·∫°o nh∆∞ng kh√¥ng th·ªÉ l∆∞u l√™n Google Drive")
            
            return vectorstore, current_metadata, metadata_to_save['stats']
    
    return None, {}, {}

# H√†m ph√¢n lo·∫°i c√¢u h·ªèi
def classify_question(question):
    """Ph√¢n lo·∫°i c√¢u h·ªèi ƒë·ªÉ ƒë∆∞a ra ph·∫£n h·ªìi ph√π h·ª£p"""
    question_lower = question.lower()
    
    categories = {
        "Tuy·ªÉn sinh": ["tuy·ªÉn sinh", "ƒëƒÉng k√Ω", "h·ªì s∆°", "ƒëi·ªÉm chu·∫©n", "x√©t tuy·ªÉn", "k·ª≥ thi", "th·ªß t·ª•c", "ƒëƒÉng k√≠", "n·ªôp h·ªì s∆°"],
        "H·ªçc ph√≠": ["h·ªçc ph√≠", "chi ph√≠", "mi·ªÖn gi·∫£m", "h·ªçc b·ªïng", "tr·ª£ c·∫•p", "t√†i ch√≠nh", "ph√≠", "ti·ªÅn"],
        "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o": ["ch∆∞∆°ng tr√¨nh", "m√¥n h·ªçc", "t√≠n ch·ªâ", "khoa", "ng√†nh", "th·ªùi kh√≥a bi·ªÉu", "h·ªçc t·∫≠p", "ƒë√†o t·∫°o"],
        "Sinh ho·∫°t sinh vi√™n": ["c√¢u l·∫°c b·ªô", "ho·∫°t ƒë·ªông", "th·ªÉ thao", "vƒÉn h√≥a", "t√¨nh nguy·ªán", "sinh ho·∫°t", "s·ª± ki·ªán"],
        "H·ªó tr·ª£ sinh vi√™n": ["t∆∞ v·∫•n", "h·ªó tr·ª£", "k√Ω t√∫c x√°", "th∆∞ vi·ªán", "c∆° s·ªü v·∫≠t ch·∫•t", "ktx", "·ªü", "ch·ªó ·ªü"],
        "T·ªët nghi·ªáp": ["t·ªët nghi·ªáp", "b·∫±ng c·∫•p", "th·ª±c t·∫≠p", "vi·ªác l√†m", "ngh·ªÅ nghi·ªáp", "ra tr∆∞·ªùng", "th·ª±c t·∫ø"]
    }
    
    for category, keywords in categories.items():
        if any(keyword in question_lower for keyword in keywords):
            return category
    return "Kh√°c"

# H√†m t·∫°o badge cho danh m·ª•c
def get_category_badge(category):
    """T·∫°o badge HTML cho danh m·ª•c c√¢u h·ªèi"""
    badge_classes = {
        "Tuy·ªÉn sinh": "badge-tuyensinh",
        "H·ªçc ph√≠": "badge-hocphi", 
        "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o": "badge-chuongtrinh",
        "Sinh ho·∫°t sinh vi√™n": "badge-sinhhoat",
        "H·ªó tr·ª£ sinh vi√™n": "badge-hotro",
        "T·ªët nghi·ªáp": "badge-totnghiep"
    }
    
    badge_class = badge_classes.get(category, "badge-tuyensinh")
    return f'<span class="category-badge {badge_class}">{category}</span>'

# H√†m kh·ªüi t·∫°o Conversational Retrieval Chain
def create_conversational_chain(vector_store, llm):
    prompt = PromptTemplate(
        template=COUNSELING_PROMPT_TEMPLATE,
        input_variables=["context", "chat_history", "question"]
    )
    
    memory = ConversationBufferWindowMemory(
        k=5,
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(search_kwargs={"k": 5}),
        memory=memory,
        return_source_documents=True,
        combine_docs_chain_kwargs={"prompt": prompt}
    )

# H√†m k·∫øt n·ªëi LLM
@st.cache_resource
def get_gemini_llm():
    return GoogleGenerativeAI(
        model="gemini-1.5-flash",
        google_api_key=gemini_api_key,
        temperature=0.3,
        max_output_tokens=1000
    )

@st.cache_resource
def get_deepseek_llm():
    from langchain_openai import ChatOpenAI
    return ChatOpenAI(
        openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
        openai_api_base="https://api.deepseek.com",
        model_name="deepseek-chat"
    )
# H√†m tr·∫£ l·ªùi t·ª´ API b√™n ngo√†i
def answer_from_external_api(prompt, llm, question_category):
    enhanced_prompt = f"""
    B·∫°n l√† chuy√™n gia t∆∞ v·∫•n {question_category.lower()} c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh.
    
    C√¢u h·ªèi: {prompt}
    
    H√£y tr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán, chuy√™n nghi·ªáp v√† h·ªØu √≠ch. 
    Cung c·∫•p th√¥ng tin ch√≠nh x√°c v·ªÅ ƒê·∫°i h·ªçc Lu·∫≠t TPHCM.
    N·∫øu kh√¥ng c√≥ th√¥ng tin c·ª• th·ªÉ, h√£y ƒë∆∞a ra l·ªùi khuy√™n chung ph√π h·ª£p v√† 
    khuy·∫øn kh√≠ch li√™n h·ªá ph√≤ng ban c√≥ li√™n quan ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ chi ti·∫øt h∆°n.
    
    Th√¥ng tin li√™n h·ªá:
    - Ph√≤ng Tuy·ªÉn sinh: 1900 5555 14 ho·∫∑c 0879 5555 14
    - Email: tuyensinh@hcmulaw.edu.vn
    - ƒê·ªãa ch·ªâ: 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM
    """
    
    try:
        if isinstance(llm, GoogleGenerativeAI):
            response = llm.invoke(enhanced_prompt)
        else:
            response = llm.invoke(enhanced_prompt)
        return response
    except Exception as e:
        return f"Xin l·ªói, t√¥i g·∫∑p m·ªôt ch√∫t tr·ª•c tr·∫∑c k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c li√™n h·ªá tr·ª±c ti·∫øp v·ªõi ph√≤ng t∆∞ v·∫•n theo s·ªë (028) 39400 989. L·ªói: {str(e)}"

# H√†m l∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i
def save_chat_history(user_question, bot_response, question_category):
    if 'chat_logs' not in st.session_state:
        st.session_state.chat_logs = []
    
    st.session_state.chat_logs.append({
        'timestamp': datetime.now().isoformat(),
        'user_question': user_question,
        'bot_response': bot_response,
        'category': question_category
    })

# H√†m hi·ªÉn th·ªã th·ªëng k√™
def display_stats_cards(stats):
    """Hi·ªÉn th·ªã th·ªëng k√™ d∆∞·ªõi d·∫°ng cards ƒë·∫πp"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">üìÑ {stats.get('total_files', 0)}</div>
            <div class="metric-label">T·ªïng s·ªë file</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">‚úÖ {stats.get('processed_files', 0)}</div>
            <div class="metric-label">ƒê√£ x·ª≠ l√Ω</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">üìä {stats.get('total_chunks', 0)}</div>
            <div class="metric-label">Chunks d·ªØ li·ªáu</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">‚ùå {stats.get('failed_files', 0)}</div>
            <div class="metric-label">L·ªói x·ª≠ l√Ω</div>
        </div>
        """, unsafe_allow_html=True)

# H√†m hi·ªÉn th·ªã c√°c c√¢u h·ªèi g·ª£i √Ω
def display_quick_questions():
    """Hi·ªÉn th·ªã c√°c c√¢u h·ªèi g·ª£i √Ω"""
    st.markdown("### üí° C√¢u h·ªèi th∆∞·ªùng g·∫∑p")
    
    quick_questions = [
        "üìù Th·ªß t·ª•c ƒëƒÉng k√Ω x√©t tuy·ªÉn nh∆∞ th·∫ø n√†o?",
        "üí∞ H·ªçc ph√≠ c·ªßa tr∆∞·ªùng l√† bao nhi·ªÅu?", 
        "üìö C√°c ng√†nh h·ªçc c·ªßa tr∆∞·ªùng c√≥ g√¨?",
        "üè† Tr∆∞·ªùng c√≥ k√Ω t√∫c x√° kh√¥ng?",
        "üéì C∆° h·ªôi vi·ªác l√†m sau t·ªët nghi·ªáp?",
        "üìû Th√¥ng tin li√™n h·ªá t∆∞ v·∫•n?"
    ]
    
    cols = st.columns(2)
    for i, question in enumerate(quick_questions):
        with cols[i % 2]:
            if st.button(question, key=f"quick_{i}", use_container_width=True):
                # Thay v√¨ d√πng suggested_question, ta s·∫Ω x·ª≠ l√Ω tr·ª±c ti·∫øp
                clean_question = question.split(" ", 1)[1]  # B·ªè emoji
                
                # Th√™m v√†o messages ngay l·∫≠p t·ª©c
                st.session_state.messages.append({"role": "user", "content": clean_question})
                
                # Set flag ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi trong main loop
                st.session_state.process_question = clean_question
                st.session_state.first_visit = False
                
                # Rerun ƒë·ªÉ c·∫≠p nh·∫≠t UI
                st.rerun()
# H√†m hi·ªÉn th·ªã c√°c t√≠nh nƒÉng
def display_features():
    """Hi·ªÉn th·ªã c√°c t√≠nh nƒÉng c·ªßa chatbot"""
    st.markdown("### üöÄ T√≠nh nƒÉng h·ªó tr·ª£")
    
    st.markdown("""
    <div class="feature-grid">
        <div class="feature-card">
            <div class="feature-icon">üéØ</div>
            <div class="feature-title">T∆∞ v·∫•n tuy·ªÉn sinh</div>
            <div class="feature-description">H∆∞·ªõng d·∫´n chi ti·∫øt v·ªÅ th·ªß t·ª•c ƒëƒÉng k√Ω, ƒëi·ªÉm chu·∫©n, ph∆∞∆°ng th·ª©c x√©t tuy·ªÉn</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">üí°</div>
            <div class="feature-title">H·ªó tr·ª£ sinh vi√™n</div>
            <div class="feature-description">Th√¥ng tin v·ªÅ k√Ω t√∫c x√°, h·ªçc b·ªïng, ho·∫°t ƒë·ªông ngo·∫°i kh√≥a</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">üìö</div>
            <div class="feature-title">Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o</div>
            <div class="feature-description">Chi ti·∫øt v·ªÅ c√°c ng√†nh h·ªçc, m√¥n h·ªçc, t√≠n ch·ªâ v√† k·∫ø ho·∫°ch h·ªçc t·∫≠p</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">üåü</div>
            <div class="feature-title">T∆∞ v·∫•n ngh·ªÅ nghi·ªáp</div>
            <div class="feature-description">ƒê·ªãnh h∆∞·ªõng ngh·ªÅ nghi·ªáp, c∆° h·ªôi vi·ªác l√†m sau t·ªët nghi·ªáp</div>
        </div>
    </div>
    """, unsafe_allow_html=True)


def check_admin_login():
    """Ki·ªÉm tra ƒëƒÉng nh·∫≠p admin"""
    if 'admin_logged_in' not in st.session_state:
        st.session_state.admin_logged_in = False
    
    return st.session_state.admin_logged_in

def admin_login_form():
    """Form ƒëƒÉng nh·∫≠p admin"""
    st.markdown("### üîê ƒêƒÉng nh·∫≠p Admin")
    
    with st.form("admin_login"):
        username = st.text_input("üë§ T√™n ƒëƒÉng nh·∫≠p:")
        password = st.text_input("üîí M·∫≠t kh·∫©u:", type="password")
        login_btn = st.form_submit_button("üöÄ ƒêƒÉng nh·∫≠p", use_container_width=True)
        
        if login_btn:
            if username == "lephung" and password == "Phung@1234":
                st.session_state.admin_logged_in = True
                st.success("‚úÖ ƒêƒÉng nh·∫≠p th√†nh c√¥ng!")
                st.rerun()
            else:
                st.error("‚ùå Sai t√™n ƒëƒÉng nh·∫≠p ho·∫∑c m·∫≠t kh·∫©u!")
# Giao di·ªán ch√≠nh
# Giao di·ªán ch√≠nh
def main():
    # Ki·ªÉm tra query parameter ƒë·ªÉ force rebuild
    query_params = st.query_params
    if 'rebuild' in query_params:
        st.cache_resource.clear()
        if 'vector_store' in st.session_state:
            del st.session_state.vector_store
        st.success("üîÑ ƒêang rebuild vectorstore...")
        # X√≥a param sau khi x·ª≠ l√Ω
        st.query_params.clear()
    # Kh·ªüi t·∫°o session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "first_visit" not in st.session_state:
        st.session_state.first_visit = True
    if "admin_logged_in" not in st.session_state:
        st.session_state.admin_logged_in = False
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None
    if "file_stats" not in st.session_state:
        st.session_state.file_stats = None

    # Header v·ªõi animation
    st.markdown("""
<div class="main-header">
    <div class="header-title">
        <img src="data:image/jpg;base64,{}" alt="Logo" class="header-logo">
        <h1>Chatbot T∆∞ V·∫•n Tuy·ªÉn Sinh</h1>
    </div>
    <h3>Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh</h3>
    <p>ü§ñ H·ªó tr·ª£ 24/7 | üí¨ T∆∞ v·∫•n chuy√™n nghi·ªáp</p>
</div>
""".format(get_base64_of_image("logo.jpg")), unsafe_allow_html=True)

    # Sidebar c·∫£i ti·∫øn
   

# KH·ªûI T·∫†O VECTOR STORE (CH·∫†Y NG·∫¶M, KH√îNG HI·ªÇN TH·ªä)
    with st.spinner("üîÑ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng..."):
        vectorstore, file_metadata, stats = initialize_vectorstore()
        st.session_state.vector_store = vectorstore
        st.session_state.file_stats = stats
    force_rebuild = st.session_state.get('force_rebuild', False)
    
    if not st.session_state.get('vector_store') or force_rebuild:
        with st.spinner("üîÑ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng..."):
            vectorstore, file_metadata, stats = initialize_vectorstore(force_rebuild)
            st.session_state.vector_store = vectorstore
            st.session_state.file_stats = stats
            
            # Clear force rebuild flag after processing
            if 'force_rebuild' in st.session_state:
                del st.session_state.force_rebuild
        
    # Sidebar ti·∫øp t·ª•c v·ªõi th√¥ng tin chung
  

    # X√°c ƒë·ªãnh llm_option d·ª±a tr√™n admin status
    if not check_admin_login():
        llm_option = "Gemini"  # M·∫∑c ƒë·ªãnh cho user th∆∞·ªùng
    
    # Ki·ªÉm tra API keys
    if llm_option == "Gemini" and not gemini_api_key:
        st.error("‚ö†Ô∏è Vui l√≤ng cung c·∫•p GEMINI_API_KEY trong file .env")
        st.stop()
    elif llm_option == "DeepSeek" and not os.getenv("DEEPSEEK_API_KEY"):
        st.error("‚ö†Ô∏è Vui l√≤ng cung c·∫•p DEEPSEEK_API_KEY trong file .env")
        st.stop()

    # Kh·ªüi t·∫°o LLM
    if llm_option == "Gemini":
        llm = get_gemini_llm()
    else:
        llm = get_deepseek_llm()

    # Kh·ªüi t·∫°o chain n·∫øu c√≥ vector store
    chain = None
    if st.session_state.get('vector_store'):
        chain = create_conversational_chain(st.session_state.vector_store, llm)

    # N·ªôi dung ch√≠nh
    if (not st.session_state.messages or len(st.session_state.messages) == 0) and st.session_state.first_visit:
    # Ch·ªâ hi·ªÉn th·ªã c√¢u h·ªèi g·ª£i √Ω
     display_quick_questions()
        
        # H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
    st.markdown("""
        <div class="info-card">
            <h4>üí° C√°ch s·ª≠ d·ª•ng hi·ªáu qu·∫£:</h4>
            <ul>
                <li>üéØ ƒê·∫∑t c√¢u h·ªèi c·ª• th·ªÉ v·ªÅ lƒ©nh v·ª±c b·∫°n quan t√¢m</li>
                <li>üìù Cung c·∫•p th√¥ng tin chi ti·∫øt ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n ch√≠nh x√°c</li>
                <li>üîÑ Ti·∫øp t·ª•c h·ªèi ƒë·ªÉ l√†m r√µ th√™m th√¥ng tin</li>
                <li>üìû Li√™n h·ªá tr·ª±c ti·∫øp n·∫øu c·∫ßn h·ªó tr·ª£ kh·∫©n c·∫•p</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat v·ªõi style m·ªõi
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant" and "category" in message:
                # Hi·ªÉn th·ªã badge danh m·ª•c
                st.markdown(get_category_badge(message["category"]), unsafe_allow_html=True)
            st.markdown(message["content"])

    # Ki·ªÉm tra xem c√≥ c√¢u h·ªèi t·ª´ button kh√¥ng
    prompt = None
    if hasattr(st.session_state, 'process_question') and st.session_state.process_question:
        prompt = st.session_state.process_question
        # X√≥a flag sau khi l·∫•y
        del st.session_state.process_question
    else:
        # Lu√¥n hi·ªÉn th·ªã khung chat input
        prompt = st.chat_input("üí¨ H√£y ƒë·∫∑t c√¢u h·ªèi c·ªßa b·∫°n...") 

    # X·ª≠ l√Ω c√¢u h·ªèi (ph·∫ßn n√†y gi·ªØ nguy√™n)
     # X·ª≠ l√Ω c√¢u h·ªèi (ph·∫ßn n√†y gi·ªØ nguy√™n)
    if prompt:
        # SET first_visit = False khi c√≥ c√¢u h·ªèi ƒë·∫ßu ti√™n
        if st.session_state.first_visit:
            st.session_state.first_visit = False
        
        # Ki·ªÉm tra xem c√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c th√™m v√†o messages ch∆∞a (t·ª´ button click)
        if not st.session_state.messages or st.session_state.messages[-1]["content"] != prompt:
            # Hi·ªÉn th·ªã c√¢u h·ªèi ng∆∞·ªùi d√πng
            with st.chat_message("user"):
                st.markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})

        # Ph√¢n lo·∫°i c√¢u h·ªèi
        question_category = classify_question(prompt)

        # X·ª≠ l√Ω v√† tr·∫£ l·ªùi
        with st.chat_message("assistant"):
            # Hi·ªÉn th·ªã badge danh m·ª•c
            st.markdown(get_category_badge(question_category), unsafe_allow_html=True)
            
            with st.spinner("ü§î ƒêang ph√¢n t√≠ch v√† t√¨m ki·∫øm th√¥ng tin..."):
                try:
                    if chain and st.session_state.get('vector_store'):
                        # S·ª≠ d·ª•ng RAG v·ªõi t√†i li·ªáu
                        response = chain({"question": prompt})
                        answer = response["answer"]
                        
                        # Hi·ªÉn th·ªã ngu·ªìn tham kh·∫£o
                        #if response.get("source_documents"):
                            #st.markdown("---")
                            #with st.expander("üìö Ngu·ªìn tham kh·∫£o t·ª´ t√†i li·ªáu", expanded=False):
                                #for i, doc in enumerate(response["source_documents"][:3]):
                                    #st.markdown(f"""
                                    #**üìÑ Ngu·ªìn {i+1}:** `{doc.metadata.get('source_file', 'N/A')}`
                                    
                                    #*N·ªôi dung:* {doc.page_content[:300]}...
                                    #""")
                    else:
                        # S·ª≠ d·ª•ng AI thu·∫ßn t√∫y
                        answer = answer_from_external_api(prompt, llm, question_category)
                    
                    st.markdown(answer)
                    
                    # L∆∞u l·ªãch s·ª≠
                    save_chat_history(prompt, answer, question_category)
                    
                except Exception as e:
                    error_msg = f"""
                    üîß **Xin l·ªói, h·ªá th·ªëng g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t**
                    
                    Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c li√™n h·ªá tr·ª±c ti·∫øp:
                    üìû **Hotline t∆∞ v·∫•n:** (028) 39400 989
                    üìß **Email:** tuyensinh@hcmulaw.edu.vn
                    
                    *M√£ l·ªói: {str(e)}*
                    """
                    st.error(error_msg)
                    answer = error_msg

            # L∆∞u tin nh·∫Øn v·ªõi danh m·ª•c
            st.session_state.messages.append({
                "role": "assistant", 
                "content": answer,
                "category": question_category
            })

    # Footer chuy√™n nghi·ªáp
    st.markdown("---")
    st.markdown("""
    <div class="footer">
        <div class="footer-grid">
            <div class="footer-section">
                <h4>üèõÔ∏è Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t TPHCM</h4>
                <p>üìç 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM</p>
                <p>üìû ƒêi·ªán tho·∫°i: (028) 39400 989</p>
                <p>üìß Email: ict@hcmulaw.edu.vn</p>
            </div>
            <div class="footer-section">
                <h4>üìû Hotline t∆∞ v·∫•n</h4>
                <p>üéì Tuy·ªÉn sinh: 1900 5555 14 ho·∫∑c 0879 5555 14</p>
                <p>üë• C√¥ng t√°c SV: (028) 39400 989</p>
                <p>üè† K√Ω t√∫c x√°: (028) 39400 989</p>
                <p>üí∞ H·ªçc ph√≠: (028) 39400 989</p>
            </div>
            <div class="footer-section">
                <h4>üåê Li√™n k·∫øt</h4>
                <p>üåç Website: www.hcmulaw.edu.vn</p>
                <p>üìò Facebook: /hcmulaw</p>
                <p>üì∫ YouTube: /hcmulaw</p>
                <p>üìß Zalo:</p>
            </div>
        </div>
        <div style="text-align: center; margin-top: 1rem; padding-top: 1rem; border-top: 1px solid rgba(255,255,255,0.2);">
            <p>ü§ñ <strong>Chatbot T∆∞ V·∫•n</strong> - Phi√™n b·∫£n 2.0 | üïí H·ªó tr·ª£ 24/7 | üí¨ Ph·∫£n h·ªìi t·ª©c th√¨</p>
            <p style="font-size: 0.8em; opacity: 0.8;">ƒê∆∞·ª£c ph√°t tri·ªÉn b·ªüi Lvphung - CNTT - ƒê·∫°i h·ªçc Lu·∫≠t TPHCM</p>
        </div>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
