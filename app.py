import streamlit as st
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain_google_genai import GoogleGenerativeAI
from langchain_openai import OpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
import os
import pickle
import json
import pandas as pd
from datetime import datetime
import re
import gdown
import requests
from io import BytesIO
import tempfile
import glob
from pathlib import Path
from dotenv import load_dotenv



# Cáº¥u hÃ¬nh trang
st.set_page_config(
    page_title="Chatbot TÆ° Váº¥n - Äáº¡i há»c Luáº­t TPHCM",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS tÃ¹y chá»‰nh nÃ¢ng cao
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    * {
        font-family: 'Inter', sans-serif;
    }
    
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 50%, #1e3c72 100%);
        padding: 2rem;
        border-radius: 20px;
        color: black;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(30, 60, 114, 0.3);
        position: relative;
        overflow: hidden;
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
        animation: shimmer 3s infinite;
    }
    
    @keyframes shimmer {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    
    .main-header h1 {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        position: relative;
        z-index: 1;
    }
    
    .main-header h3 {
        font-size: 1.3rem;
        font-weight: 500;
        margin-bottom: 0.5rem;
        opacity: 0.9;
        position: relative;
        z-index: 1;
    }
    
    .main-header p {
        font-size: 1rem;
        opacity: 0.8;
        position: relative;
        z-index: 1;
    }
    
    .chat-message {
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1.5rem 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        backdrop-filter: blur(10px);
        transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    
    .chat-message:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    
    .user-message {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 5px solid #2196f3;
        color: #1565c0;
    }
    
    .assistant-message {
        background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
        border-left: 5px solid #9c27b0;
        color: #6a1b9a;
    }
    
    .sidebar-info {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
    }
    
    .file-status {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #4caf50;
        box-shadow: 0 2px 8px rgba(76, 175, 80, 0.2);
    }
    
    .metric-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        border: 1px solid #e9ecef;
        margin: 0.5rem 0;
        transition: transform 0.2s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.15);
    }
    
    .metric-value {
        font-size: 2rem;
        font-weight: 700;
        color: #1e3c72;
        margin-bottom: 0.5rem;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #6c757d;
        font-weight: 500;
    }
    
    .info-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
        border: 1px solid #ffb74d;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(255, 183, 77, 0.2);
    }
    
    .success-card {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        border: 1px solid #4caf50;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(76, 175, 80, 0.2);
    }
    
    .warning-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffcc80 100%);
        border: 1px solid #ff9800;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 3px 10px rgba(255, 152, 0, 0.2);
    }
    
    .category-badge {
        display: inline-block;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.8rem;
        font-weight: 600;
        margin: 0.2rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    .badge-tuyensinh {
        background: linear-gradient(135deg, #e3f2fd 0%, #90caf9 100%);
        color: #1565c0;
    }
    
    .badge-hocphi {
        background: linear-gradient(135deg, #e8f5e8 0%, #a5d6a7 100%);
        color: #2e7d32;
    }
    
    .badge-chuongtrinh {
        background: linear-gradient(135deg, #f3e5f5 0%, #ce93d8 100%);
        color: #6a1b9a;
    }
    
    .badge-sinhhoat {
        background: linear-gradient(135deg, #fff3e0 0%, #ffcc80 100%);
        color: #e65100;
    }
    
    .badge-hotro {
        background: linear-gradient(135deg, #fce4ec 0%, #f8bbd9 100%);
        color: #c2185b;
    }
    
    .badge-totnghiep {
        background: linear-gradient(135deg, #e0f2f1 0%, #80cbc4 100%);
        color: #00695c;
    }
    
    .quick-actions {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 1rem;
        margin: 1.5rem 0;
    }
    
    .action-button {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border: 2px solid #e9ecef;
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        cursor: pointer;
        transition: all 0.3s ease;
        text-decoration: none;
        color: #495057;
    }
    
    .action-button:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 25px rgba(0,0,0,0.15);
        border-color: #2196f3;
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
    }
    
    .action-icon {
        font-size: 2rem;
        margin-bottom: 0.5rem;
        display: block;
    }
    
    .footer {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-top: 3rem;
        text-align: center;
    }
    
    .footer-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
        gap: 2rem;
        margin-bottom: 1rem;
    }
    
    .footer-section h4 {
        color: #90caf9;
        margin-bottom: 1rem;
        font-weight: 600;
    }
    
    .footer-section p {
        margin-bottom: 0.5rem;
        opacity: 0.9;
    }
    
    .stSelectbox > div > div {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border-radius: 10px;
        border: 2px solid #e9ecef;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #2196f3 0%, #1976d2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #1976d2 0%, #1565c0 100%);
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(33, 150, 243, 0.3);
    }
    
    .chat-input {
        border-radius: 25px !important;
        border: 2px solid #e9ecef !important;
        padding: 1rem 1.5rem !important;
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%) !important;
    }
    
    .stChatInput > div > div > textarea {
        border-radius: 25px;
        border: 2px solid #e9ecef;
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
    }
    
    .loading-container {
        display: flex;
        align-items: center;
        justify-content: center;
        padding: 2rem;
    }
    
    .loading-spinner {
        width: 40px;
        height: 40px;
        border: 4px solid #e9ecef;
        border-top: 4px solid #2196f3;
        border-radius: 50%;
        animation: spin 1s linear infinite;
    }
    
    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
        gap: 1.5rem;
        margin: 2rem 0;
    }
    
    .feature-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        border: 1px solid #e9ecef;
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 25px rgba(0,0,0,0.15);
    }
    
    .feature-icon {
        font-size: 3rem;
        margin-bottom: 1rem;
        color: #2196f3;
    }
    
    .feature-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #1e3c72;
        margin-bottom: 0.5rem;
    }
    
    .feature-description {
        color: #6c757d;
        font-size: 0.9rem;
        line-height: 1.5;
    }
</style>
""", unsafe_allow_html=True)

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()
grok_api_key = os.getenv("GROK_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")

GDRIVE_VECTORSTORE_ID = os.getenv("GDRIVE_VECTORSTORE_ID")  # ID file pkl trÃªn GDrive
GDRIVE_METADATA_ID = os.getenv("GDRIVE_METADATA_ID")        # ID file metadata trÃªn GDrive
GDRIVE_FOLDER_ID = os.getenv("GDRIVE_FOLDER_ID")            # ID folder chá»©a vectorstore
# Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n
DOCUMENTS_PATH = "documents"
VECTORSTORE_PATH = "vectorstore"
CACHE_PATH = "cache"

# Táº¡o cÃ¡c thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
for path in [DOCUMENTS_PATH, VECTORSTORE_PATH, CACHE_PATH]:
    Path(path).mkdir(exist_ok=True)

# Template prompt chuyÃªn biá»‡t cho tÆ° váº¥n tuyá»ƒn sinh
COUNSELING_PROMPT_TEMPLATE = """
Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n tuyá»ƒn sinh vÃ  cÃ´ng tÃ¡c sinh viÃªn cá»§a TrÆ°á»ng Äáº¡i há»c Luáº­t ThÃ nh phá»‘ Há»“ ChÃ­ Minh.
HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p vÃ  kiáº¿n thá»©c chuyÃªn mÃ´n.

NguyÃªn táº¯c tráº£ lá»i:
1. ThÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  dá»… hiá»ƒu
2. Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c, cá»¥ thá»ƒ vá» Äáº¡i há»c Luáº­t TPHCM
3. ÄÆ°a ra lá»i khuyÃªn phÃ¹ há»£p vá»›i tá»«ng trÆ°á»ng há»£p
4. HÆ°á»›ng dáº«n cÃ¡c bÆ°á»›c cáº§n thiáº¿t náº¿u cÃ³
5. LuÃ´n khuyáº¿n khÃ­ch vÃ  táº¡o Ä‘á»™ng lá»±c tÃ­ch cá»±c
6. Cung cáº¥p thÃ´ng tin liÃªn há»‡ cá»¥ thá»ƒ khi cáº§n thiáº¿t

ThÃ´ng tin tham kháº£o: {context}

Lá»‹ch sá»­ há»™i thoáº¡i: {chat_history}

CÃ¢u há»i cá»§a sinh viÃªn/thÃ­ sinh: {question}

Tráº£ lá»i (báº±ng tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p):
"""
def download_from_gdrive(file_id, output_path):
    """Download file tá»« Google Drive"""
    try:
        url = f'https://drive.google.com/uc?id={file_id}'
        gdown.download(url, output_path, quiet=True)
        return True
    except Exception as e:
        st.warning(f"KhÃ´ng thá»ƒ táº£i file tá»« Google Drive: {e}")
        return False

def upload_to_gdrive(file_path, file_id=None):
    """Upload file lÃªn Google Drive (cáº§n Google Drive API)"""
    # Táº¡m thá»i return True - cáº§n implement Google Drive API
    # Hoáº·c cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c service khÃ¡c nhÆ° Dropbox, OneDrive
    return True

def get_gdrive_file_info(file_id):
    """Láº¥y thÃ´ng tin file tá»« Google Drive"""
    try:
        # API call Ä‘á»ƒ láº¥y thÃ´ng tin file (modified time, size, etc.)
        # Táº¡m thá»i return None
        return None
    except:
        return None

# Khá»Ÿi táº¡o embeddings vá»›i model phÃ¹ há»£p tiáº¿ng Viá»‡t
@st.cache_resource
def load_embeddings():
    return HuggingFaceEmbeddings(
        model_name="keepitreal/vietnamese-sbert",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

embeddings = load_embeddings()

# HÃ m láº¥y danh sÃ¡ch file tá»« thÆ° má»¥c documents
def get_document_files():
    """Láº¥y danh sÃ¡ch táº¥t cáº£ file trong thÆ° má»¥c documents"""
    supported_extensions = ['*.pdf', '*.docx', '*.txt']
    files = []
    
    for ext in supported_extensions:
        files.extend(glob.glob(os.path.join(DOCUMENTS_PATH, '**', ext), recursive=True))
    
    return files

# HÃ m táº¡o hash cho file Ä‘á»ƒ kiá»ƒm tra thay Ä‘á»•i
def get_file_hash(file_path):
    """Táº¡o hash cho file Ä‘á»ƒ kiá»ƒm tra thay Ä‘á»•i"""
    stat = os.stat(file_path)
    return f"{stat.st_mtime}_{stat.st_size}"

# HÃ m kiá»ƒm tra cache vector store
def load_cached_vectorstore():
    """Load vector store tá»« Google Drive"""
    
    # Táº¡o thÆ° má»¥c táº¡m
    temp_dir = tempfile.mkdtemp()
    vectorstore_path = os.path.join(temp_dir, "vectorstore.pkl")
    metadata_path = os.path.join(temp_dir, "metadata.json")
    
    try:
        # Download vectorstore tá»« Google Drive
        if GDRIVE_VECTORSTORE_ID:
            if not download_from_gdrive(GDRIVE_VECTORSTORE_ID, vectorstore_path):
                return None, {}
        else:
            st.warning("âš ï¸ ChÆ°a cáº¥u hÃ¬nh GDRIVE_VECTORSTORE_ID")
            return None, {}
        
        # Download metadata tá»« Google Drive
        if GDRIVE_METADATA_ID:
            if not download_from_gdrive(GDRIVE_METADATA_ID, metadata_path):
                return None, {}
        else:
            st.warning("âš ï¸ ChÆ°a cáº¥u hÃ¬nh GDRIVE_METADATA_ID")
            return None, {}
        
        # Load vectorstore
        with open(vectorstore_path, 'rb') as f:
            vectorstore = pickle.load(f)
        
        # Load metadata
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # Dá»n dáº¹p file táº¡m
        os.remove(vectorstore_path)
        os.remove(metadata_path)
        os.rmdir(temp_dir)
        
        return vectorstore, metadata
        
    except Exception as e:
        st.error(f"Lá»—i load vectorstore tá»« Google Drive: {e}")
        # Dá»n dáº¹p file táº¡m náº¿u cÃ³ lá»—i
        try:
            if os.path.exists(vectorstore_path):
                os.remove(vectorstore_path)
            if os.path.exists(metadata_path):
                os.remove(metadata_path)
            os.rmdir(temp_dir)
        except:
            pass
        return None, {}

# HÃ m lÆ°u vector store vÃ o cache
def save_vectorstore_cache(vectorstore, metadata):
    """LÆ°u vector store lÃªn Google Drive"""
    try:
        # Táº¡o thÆ° má»¥c táº¡m
        temp_dir = tempfile.mkdtemp()
        vectorstore_path = os.path.join(temp_dir, "vectorstore.pkl")
        metadata_path = os.path.join(temp_dir, "metadata.json")
        
        # LÆ°u vectorstore vÃ o file táº¡m
        with open(vectorstore_path, 'wb') as f:
            pickle.dump(vectorstore, f)
        
        # LÆ°u metadata vÃ o file táº¡m
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # Upload lÃªn Google Drive
        success_vectorstore = upload_to_gdrive(vectorstore_path, GDRIVE_VECTORSTORE_ID)
        success_metadata = upload_to_gdrive(metadata_path, GDRIVE_METADATA_ID)
        
        # Dá»n dáº¹p file táº¡m
        os.remove(vectorstore_path)
        os.remove(metadata_path)
        os.rmdir(temp_dir)
        
        if success_vectorstore and success_metadata:
            st.success("âœ… ÄÃ£ lÆ°u vectorstore lÃªn Google Drive!")
            return True
        else:
            st.error("âŒ Lá»—i upload lÃªn Google Drive")
            return False
            
    except Exception as e:
        st.error(f"Lá»—i lÆ°u vectorstore lÃªn Google Drive: {e}")
        return False

# HÃ m kiá»ƒm tra xem cÃ³ cáº§n rebuild vector store khÃ´ng
def need_rebuild_vectorstore():
    """ĞšĞ¸á»ƒm tra xem cÃ³ cáº§n rebuild vector store khÃ´ng"""
    current_files = get_document_files()
    
    if not current_files:
        return False, {}, []
    
    # Táº¡o metadata hiá»‡n táº¡i
    current_metadata = {}
    for file_path in current_files:
        current_metadata[file_path] = get_file_hash(file_path)
    
    # Load cached metadata tá»« Google Drive
    _, cached_metadata = load_cached_vectorstore()
    
    # So sÃ¡nh
    if current_metadata != cached_metadata.get('files', {}):
        return True, current_metadata, current_files
    
    return False, current_metadata, current_files
def check_gdrive_connection():
    """Kiá»ƒm tra káº¿t ná»‘i vÃ  cáº¥u hÃ¬nh Google Drive"""
    issues = []
    
    if not GDRIVE_VECTORSTORE_ID:
        issues.append("âŒ Thiáº¿u GDRIVE_VECTORSTORE_ID")
    
    if not GDRIVE_METADATA_ID:
        issues.append("âŒ Thiáº¿u GDRIVE_METADATA_ID")
    
    if not GDRIVE_FOLDER_ID:
        issues.append("âš ï¸ Thiáº¿u GDRIVE_FOLDER_ID (tÃ¹y chá»n)")
    
    return len(issues) == 0, issues

# HÃ m xá»­ lÃ½ file tÃ i liá»‡u
def process_documents(file_paths):
    """Xá»­ lÃ½ danh sÃ¡ch file tÃ i liá»‡u"""
    documents = []
    processed_files = []
    failed_files = []
    
    for file_path in file_paths:
        try:
            file_extension = Path(file_path).suffix.lower()
            
            if file_extension == ".pdf":
                loader = PyPDFLoader(file_path)
            elif file_extension == ".docx":
                loader = Docx2txtLoader(file_path)
            elif file_extension == ".txt":
                loader = TextLoader(file_path, encoding='utf-8')
            else:
                failed_files.append(f"{file_path} (khÃ´ng há»— trá»£)")
                continue
            
            docs = loader.load()
            
            # ThÃªm metadata
            for doc in docs:
                doc.metadata['source_file'] = os.path.basename(file_path)
                doc.metadata['file_path'] = file_path
                doc.metadata['processed_time'] = datetime.now().isoformat()
            
            documents.extend(docs)
            processed_files.append(file_path)
            
        except Exception as e:
            failed_files.append(f"{file_path} (lá»—i: {str(e)})")
    
    return documents, processed_files, failed_files

# HÃ m táº¡o vector store
def create_vector_store(documents):
    """Táº¡o vector store tá»« documents"""
    if not documents:
        return None
        
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=['\n\n', '\n', '.', '!', '?', ';', ':', ' ']
    )
    texts = text_splitter.split_documents(documents)
    
    # Lá»c bá» cÃ¡c chunk quÃ¡ ngáº¯n
    texts = [text for text in texts if len(text.page_content.strip()) > 50]
    
    if not texts:
        return None
        
    vector_store = FAISS.from_documents(texts, embeddings)
    return vector_store

# HÃ m khá»Ÿi táº¡o hoáº·c load vector store
@st.cache_resource
def initialize_vectorstore():
    """Khá»Ÿi táº¡o hoáº·c load vector store"""
    need_rebuild, current_metadata, current_files = need_rebuild_vectorstore()
    
    if not need_rebuild:
        # Load tá»« cache
        vectorstore, cached_metadata = load_cached_vectorstore()
        if vectorstore:
            return vectorstore, cached_metadata.get('files', {}), cached_metadata.get('stats', {})
    
    # Rebuild vector store
    if not current_files:
        return None, {}, {}
    
    with st.spinner("ğŸ”„ Äang xá»­ lÃ½ tÃ i liá»‡u..."):
        documents, processed_files, failed_files = process_documents(current_files)
        
        if not documents:
            return None, {}, {}
        
        vectorstore = create_vector_store(documents)
        
        if vectorstore:
            # Táº¡o metadata Ä‘á»ƒ lÆ°u
            metadata_to_save = {
                'files': current_metadata,
                'stats': {
                    'total_files': len(current_files),
                    'processed_files': len(processed_files),
                    'failed_files': len(failed_files),
                    'total_chunks': vectorstore.index.ntotal,
                    'last_updated': datetime.now().isoformat()
                },
                'processed_files': processed_files,
                'failed_files': failed_files
            }
            
            # LÆ°u cache
            save_vectorstore_cache(vectorstore, metadata_to_save)
            
            return vectorstore, current_metadata, metadata_to_save['stats']
    
    return None, {}, {}

# HÃ m phÃ¢n loáº¡i cÃ¢u há»i
def classify_question(question):
    """PhÃ¢n loáº¡i cÃ¢u há»i Ä‘á»ƒ Ä‘Æ°a ra pháº£n há»“i phÃ¹ há»£p"""
    question_lower = question.lower()
    
    categories = {
        "Tuyá»ƒn sinh": ["tuyá»ƒn sinh", "Ä‘Äƒng kÃ½", "há»“ sÆ¡", "Ä‘iá»ƒm chuáº©n", "xÃ©t tuyá»ƒn", "ká»³ thi", "thá»§ tá»¥c", "Ä‘Äƒng kÃ­", "ná»™p há»“ sÆ¡"],
        "Há»c phÃ­": ["há»c phÃ­", "chi phÃ­", "miá»…n giáº£m", "há»c bá»•ng", "trá»£ cáº¥p", "tÃ i chÃ­nh", "phÃ­", "tiá»n"],
        "ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o": ["chÆ°Æ¡ng trÃ¬nh", "mÃ´n há»c", "tÃ­n chá»‰", "khoa", "ngÃ nh", "thá»i khÃ³a biá»ƒu", "há»c táº­p", "Ä‘Ã o táº¡o"],
        "Sinh hoáº¡t sinh viÃªn": ["cÃ¢u láº¡c bá»™", "hoáº¡t Ä‘á»™ng", "thá»ƒ thao", "vÄƒn hÃ³a", "tÃ¬nh nguyá»‡n", "sinh hoáº¡t", "sá»± kiá»‡n"],
        "Há»— trá»£ sinh viÃªn": ["tÆ° váº¥n", "há»— trá»£", "kÃ½ tÃºc xÃ¡", "thÆ° viá»‡n", "cÆ¡ sá»Ÿ váº­t cháº¥t", "ktx", "á»Ÿ", "chá»— á»Ÿ"],
        "Tá»‘t nghiá»‡p": ["tá»‘t nghiá»‡p", "báº±ng cáº¥p", "thá»±c táº­p", "viá»‡c lÃ m", "nghá» nghiá»‡p", "ra trÆ°á»ng", "thá»±c táº¿"]
    }
    
    for category, keywords in categories.items():
        if any(keyword in question_lower for keyword in keywords):
            return category
    return "KhÃ¡c"

# HÃ m táº¡o badge cho danh má»¥c
def get_category_badge(category):
    """Táº¡o badge HTML cho danh má»¥c cÃ¢u há»i"""
    badge_classes = {
        "Tuyá»ƒn sinh": "badge-tuyensinh",
        "Há»c phÃ­": "badge-hocphi", 
        "ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o": "badge-chuongtrinh",
        "Sinh hoáº¡t sinh viÃªn": "badge-sinhhoat",
        "Há»— trá»£ sinh viÃªn": "badge-hotro",
        "Tá»‘t nghiá»‡p": "badge-totnghiep"
    }
    
    badge_class = badge_classes.get(category, "badge-tuyensinh")
    return f'<span class="category-badge {badge_class}">{category}</span>'

# HÃ m khá»Ÿi táº¡o Conversational Retrieval Chain
def create_conversational_chain(vector_store, llm):
    prompt = PromptTemplate(
        template=COUNSELING_PROMPT_TEMPLATE,
        input_variables=["context", "chat_history", "question"]
    )
    
    memory = ConversationBufferWindowMemory(
        k=5,
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(search_kwargs={"k": 5}),
        memory=memory,
        return_source_documents=True,
        combine_docs_chain_kwargs={"prompt": prompt}
    )

# HÃ m káº¿t ná»‘i LLM
@st.cache_resource
def get_gemini_llm():
    return GoogleGenerativeAI(
        model="gemini-1.5-flash",
        google_api_key=gemini_api_key,
        temperature=0.3,
        max_output_tokens=1000
    )

@st.cache_resource
def get_deepseek_llm():
    from langchain_openai import ChatOpenAI
    return ChatOpenAI(
        openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
        openai_api_base="https://api.deepseek.com",
        model_name="deepseek-chat"
    )
# HÃ m tráº£ lá»i tá»« API bÃªn ngoÃ i
def answer_from_external_api(prompt, llm, question_category):
    enhanced_prompt = f"""
    Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n {question_category.lower()} cá»§a TrÆ°á»ng Äáº¡i há»c Luáº­t ThÃ nh phá»‘ Há»“ ChÃ­ Minh.
    
    CÃ¢u há»i: {prompt}
    
    HÃ£y tráº£ lá»i má»™t cÃ¡ch thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  há»¯u Ã­ch. 
    Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vá» Äáº¡i há»c Luáº­t TPHCM.
    Náº¿u khÃ´ng cÃ³ thÃ´ng tin cá»¥ thá»ƒ, hÃ£y Ä‘Æ°a ra lá»i khuyÃªn chung phÃ¹ há»£p vÃ  
    khuyáº¿n khÃ­ch liÃªn há»‡ phÃ²ng ban cÃ³ liÃªn quan Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ chi tiáº¿t hÆ¡n.
    
    ThÃ´ng tin liÃªn há»‡:
    - PhÃ²ng Tuyá»ƒn sinh: (028) 3838 5052
    - PhÃ²ng CÃ´ng tÃ¡c sinh viÃªn: (028) 3838 5053
    - Email: tuyensinh@hcmulaw.edu.vn
    - Äá»‹a chá»‰: 2 Nguyá»…n Táº¥t ThÃ nh, PhÆ°á»ng 12, Quáº­n 4, TP.HCM
    """
    
    try:
        if isinstance(llm, GoogleGenerativeAI):
            response = llm.invoke(enhanced_prompt)
        else:
            response = llm.invoke(enhanced_prompt)
        return response
    except Exception as e:
        return f"Xin lá»—i, tÃ´i gáº·p má»™t chÃºt trá»¥c tráº·c ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ trá»±c tiáº¿p vá»›i phÃ²ng tÆ° váº¥n theo sá»‘ (028) 3838 5052. Lá»—i: {str(e)}"

# HÃ m lÆ°u lá»‹ch sá»­ há»™i thoáº¡i
def save_chat_history(user_question, bot_response, question_category):
    if 'chat_logs' not in st.session_state:
        st.session_state.chat_logs = []
    
    st.session_state.chat_logs.append({
        'timestamp': datetime.now().isoformat(),
        'user_question': user_question,
        'bot_response': bot_response,
        'category': question_category
    })

# HÃ m hiá»ƒn thá»‹ thá»‘ng kÃª
def display_stats_cards(stats):
    """Hiá»ƒn thá»‹ thá»‘ng kÃª dÆ°á»›i dáº¡ng cards Ä‘áº¹p"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">ğŸ“„ {stats.get('total_files', 0)}</div>
            <div class="metric-label">Tá»•ng sá»‘ file</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">âœ… {stats.get('processed_files', 0)}</div>
            <div class="metric-label">ÄÃ£ xá»­ lÃ½</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">ğŸ“Š {stats.get('total_chunks', 0)}</div>
            <div class="metric-label">Chunks dá»¯ liá»‡u</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">âŒ {stats.get('failed_files', 0)}</div>
            <div class="metric-label">Lá»—i xá»­ lÃ½</div>
        </div>
        """, unsafe_allow_html=True)

# HÃ m hiá»ƒn thá»‹ cÃ¡c cÃ¢u há»i gá»£i Ã½
def display_quick_questions():
    """Hiá»ƒn thá»‹ cÃ¡c cÃ¢u há»i gá»£i Ã½"""
    st.markdown("### ğŸ’¡ CÃ¢u há»i thÆ°á»ng gáº·p")
    
    quick_questions = [
        "ğŸ“ Thá»§ tá»¥c Ä‘Äƒng kÃ½ xÃ©t tuyá»ƒn nhÆ° tháº¿ nÃ o?",
        "ğŸ’° Há»c phÃ­ cá»§a trÆ°á»ng lÃ  bao nhiá»u?", 
        "ğŸ“š CÃ¡c ngÃ nh há»c cá»§a trÆ°á»ng cÃ³ gÃ¬?",
        "ğŸ  TrÆ°á»ng cÃ³ kÃ½ tÃºc xÃ¡ khÃ´ng?",
        "ğŸ“ CÆ¡ há»™i viá»‡c lÃ m sau tá»‘t nghiá»‡p?",
        "ğŸ“ ThÃ´ng tin liÃªn há»‡ tÆ° váº¥n?"
    ]
    
    cols = st.columns(2)
    for i, question in enumerate(quick_questions):
        with cols[i % 2]:
            if st.button(question, key=f"quick_{i}", use_container_width=True):
                st.session_state.suggested_question = question.split(" ", 1)[1]  # Bá» emoji

# HÃ m hiá»ƒn thá»‹ cÃ¡c tÃ­nh nÄƒng
def display_features():
    """Hiá»ƒn thá»‹ cÃ¡c tÃ­nh nÄƒng cá»§a chatbot"""
    st.markdown("### ğŸš€ TÃ­nh nÄƒng há»— trá»£")
    
    st.markdown("""
    <div class="feature-grid">
        <div class="feature-card">
            <div class="feature-icon">ğŸ¯</div>
            <div class="feature-title">TÆ° váº¥n tuyá»ƒn sinh</div>
            <div class="feature-description">HÆ°á»›ng dáº«n chi tiáº¿t vá» thá»§ tá»¥c Ä‘Äƒng kÃ½, Ä‘iá»ƒm chuáº©n, phÆ°Æ¡ng thá»©c xÃ©t tuyá»ƒn</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸ’¡</div>
            <div class="feature-title">Há»— trá»£ sinh viÃªn</div>
            <div class="feature-description">ThÃ´ng tin vá» kÃ½ tÃºc xÃ¡, há»c bá»•ng, hoáº¡t Ä‘á»™ng ngoáº¡i khÃ³a</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸ“š</div>
            <div class="feature-title">ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o</div>
            <div class="feature-description">Chi tiáº¿t vá» cÃ¡c ngÃ nh há»c, mÃ´n há»c, tÃ­n chá»‰ vÃ  káº¿ hoáº¡ch há»c táº­p</div>
        </div>
        <div class="feature-card">
            <div class="feature-icon">ğŸŒŸ</div>
            <div class="feature-title">TÆ° váº¥n nghá» nghiá»‡p</div>
            <div class="feature-description">Äá»‹nh hÆ°á»›ng nghá» nghiá»‡p, cÆ¡ há»™i viá»‡c lÃ m sau tá»‘t nghiá»‡p</div>
        </div>
    </div>
    """, unsafe_allow_html=True)


def check_admin_login():
    """Kiá»ƒm tra Ä‘Äƒng nháº­p admin"""
    if 'admin_logged_in' not in st.session_state:
        st.session_state.admin_logged_in = False
    
    return st.session_state.admin_logged_in

def admin_login_form():
    """Form Ä‘Äƒng nháº­p admin"""
    st.markdown("### ğŸ” ÄÄƒng nháº­p Admin")
    
    with st.form("admin_login"):
        username = st.text_input("ğŸ‘¤ TÃªn Ä‘Äƒng nháº­p:")
        password = st.text_input("ğŸ”’ Máº­t kháº©u:", type="password")
        login_btn = st.form_submit_button("ğŸš€ ÄÄƒng nháº­p", use_container_width=True)
        
        if login_btn:
            if username == "lephung" and password == "Phung@1234":
                st.session_state.admin_logged_in = True
                st.success("âœ… ÄÄƒng nháº­p thÃ nh cÃ´ng!")
                st.rerun()
            else:
                st.error("âŒ Sai tÃªn Ä‘Äƒng nháº­p hoáº·c máº­t kháº©u!")
# Giao diá»‡n chÃ­nh
def main():
    # Khá»Ÿi táº¡o session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "first_visit" not in st.session_state:
        st.session_state.first_visit = True
    if "admin_logged_in" not in st.session_state:
        st.session_state.admin_logged_in = False
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None
    if "file_stats" not in st.session_state:
        st.session_state.file_stats = None

    # Header vá»›i animation
    st.markdown("""
    <div class="main-header">
        <h1>âš–ï¸ Chatbot TÆ° Váº¥n Tuyá»ƒn Sinh</h1>
        <h3>TrÆ°á»ng Äáº¡i há»c Luáº­t ThÃ nh phá»‘ Há»“ ChÃ­ Minh</h3>
        <p>ğŸ¤– Há»— trá»£ 24/7 | ğŸ’¬ TÆ° váº¥n chuyÃªn nghiá»‡p | ğŸ“ ThÃ´ng tin chÃ­nh xÃ¡c</p>
    </div>
    """, unsafe_allow_html=True)

    # Sidebar cáº£i tiáº¿n - Bá» PHáº¦N CHECK ADMIN á» Äáº¦U
    with st.sidebar:
    # ADMIN LOGIN Äáº¦U TIÃŠN
    st.markdown("### ğŸ” Quáº£n trá»‹ viÃªn")
    is_admin = check_admin_login()
    
    if not is_admin:
        with st.expander("ÄÄƒng nháº­p Admin"):
            admin_login_form()
    else:
        if st.button("ğŸšª ÄÄƒng xuáº¥t", type="secondary", use_container_width=True):
            st.session_state.admin_logged_in = False
            st.rerun()
        
        # CHá»ˆ ADMIN Má»šI THáº¤Y TRáº NG THÃI Há»† THá»NG
        st.divider()
        st.markdown("### ğŸ“Š Tráº¡ng thÃ¡i há»‡ thá»‘ng")
        gdrive_ok, gdrive_issues = check_gdrive_connection()
        
        if gdrive_ok:
            st.markdown("""
            <div class="success-card">
                <h4>â˜ï¸ Google Drive Ä‘Ã£ káº¿t ná»‘i</h4>
                <p>Vectorstore sáº½ Ä‘Æ°á»£c táº£i tá»« cloud.</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="warning-card">
                <h4>âš ï¸ Cáº¥u hÃ¬nh Google Drive</h4>
            """, unsafe_allow_html=True)
            for issue in gdrive_issues:
                st.markdown(f"<p>{issue}</p>", unsafe_allow_html=True)
            st.markdown("</div>", unsafe_allow_html=True)
        
        # Hiá»ƒn thá»‹ thá»‘ng kÃª cho admin
        if stats:
            st.markdown("""
            <div class="success-card">
                <h4>âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!</h4>
                <p>Táº¥t cáº£ tÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  sáºµn sÃ ng phá»¥c vá»¥.</p>
            </div>
            """, unsafe_allow_html=True)
            display_stats_cards(stats)
        
        # Cáº¥u hÃ¬nh AI cho admin
        st.markdown("### ğŸ¤– Cáº¥u hÃ¬nh AI")
        llm_option = st.selectbox(
            "Chá»n mÃ´ hÃ¬nh AI:", 
            ["Gemini", "DeepSeek"],
            help="Gemini: PhÃ¹ há»£p cho cÃ¢u há»i chung\nDeepSeek: PhÃ¹ há»£p cho phÃ¢n tÃ­ch chi tiáº¿t"
        )
    
    # KHá»I Táº O VECTOR STORE (Bá»Š áº¨N CHO USER THÆ¯á»œNG)
    with st.spinner("ğŸ”„ Äang khá»Ÿi táº¡o há»‡ thá»‘ng..."):
        vectorstore, file_metadata, stats = initialize_vectorstore()
        st.session_state.vector_store = vectorstore
        st.session_state.file_stats = stats
    
    st.divider()
    
    # Thá»‘ng kÃª chat (HIá»†N CHO Táº¤T Cáº¢)
    st.markdown("### ğŸ“ˆ Thá»‘ng kÃª phiÃªn lÃ m viá»‡c")
    if 'messages' in st.session_state and st.session_state.messages:
        total_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">ğŸ’¬ {total_messages}</div>
            <div class="metric-label">CÃ¢u há»i Ä‘Ã£ há»i</div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="info-card">
            <p>ChÆ°a cÃ³ cÃ¢u há»i nÃ o trong phiÃªn nÃ y.</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.divider()
    
    # ThÃ´ng tin liÃªn há»‡ (HIá»†N CHO Táº¤T Cáº¢)
    st.markdown("### ğŸ“ ThÃ´ng tin liÃªn há»‡")
    st.markdown("""
    <div class="info-card">
        <strong>ğŸ›ï¸ Äáº¡i há»c Luáº­t TPHCM</strong><br>
        ğŸ“ 2 Nguyá»…n Táº¥t ThÃ nh, Q.4, TPHCM<br>
        ğŸ“ Tuyá»ƒn sinh: (028) 3838 5052<br>
        ğŸ“ CTSV: (028) 3838 5053<br>
        ğŸ“§ tuyensinh@hcmulaw.edu.vn<br>
        ğŸŒ www.hcmulaw.edu.vn
    </div>
    """, unsafe_allow_html=True)
            display_stats_cards(stats)
        
        st.divider()
        
        # Thá»‘ng kÃª chat
        st.markdown("### ğŸ“ˆ Thá»‘ng kÃª phiÃªn lÃ m viá»‡c")
        if 'messages' in st.session_state and st.session_state.messages:
            total_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">ğŸ’¬ {total_messages}</div>
                <div class="metric-label">CÃ¢u há»i Ä‘Ã£ há»i</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="info-card">
                <p>ChÆ°a cÃ³ cÃ¢u há»i nÃ o trong phiÃªn nÃ y.</p>
            </div>
            """, unsafe_allow_html=True)
        
        st.divider()
        
        # ThÃ´ng tin liÃªn há»‡
        st.markdown("### ğŸ“ ThÃ´ng tin liÃªn há»‡")
        st.markdown("""
        <div class="info-card">
            <strong>ğŸ›ï¸ Äáº¡i há»c Luáº­t TPHCM</strong><br>
            ğŸ“ 2 Nguyá»…n Táº¥t ThÃ nh, Q.4, TPHCM<br>
            ğŸ“ Tuyá»ƒn sinh: (028) 3838 5052<br>
            ğŸ“ CTSV: (028) 3838 5053<br>
            ğŸ“§ tuyensinh@hcmulaw.edu.vn<br>
            ğŸŒ www.hcmulaw.edu.vn
        </div>
        """, unsafe_allow_html=True)
        
        st.divider()
        
        # ADMIN LOGIN VÃ€O CUá»I
        st.markdown("### ğŸ” Quáº£n trá»‹ viÃªn")
        is_admin = check_admin_login()
        
        if not is_admin:
            with st.expander("ÄÄƒng nháº­p Admin"):
                admin_login_form()
        else:
            if st.button("ğŸšª ÄÄƒng xuáº¥t", type="secondary", use_container_width=True):
                st.session_state.admin_logged_in = False
                st.rerun()
            
            # Cáº¥u hÃ¬nh AI cho admin
            st.markdown("### ğŸ¤– Cáº¥u hÃ¬nh AI")
            llm_option = st.selectbox(
                "Chá»n mÃ´ hÃ¬nh AI:", 
                ["Gemini", "DeepSeek"],
                help="Gemini: PhÃ¹ há»£p cho cÃ¢u há»i chung\nDeepSeek: PhÃ¹ há»£p cho phÃ¢n tÃ­ch chi tiáº¿t"
            )

    # XÃ¡c Ä‘á»‹nh llm_option dá»±a trÃªn admin status
    if not check_admin_login():
        llm_option = "Gemini"  # Máº·c Ä‘á»‹nh cho user thÆ°á»ng
    
    # Kiá»ƒm tra API keys
    if llm_option == "Gemini" and not gemini_api_key:
        st.error("âš ï¸ Vui lÃ²ng cung cáº¥p GEMINI_API_KEY trong file .env")
        st.stop()
    elif llm_option == "DeepSeek" and not os.getenv("DEEPSEEK_API_KEY"):
        st.error("âš ï¸ Vui lÃ²ng cung cáº¥p DEEPSEEK_API_KEY trong file .env")
        st.stop()

    # Khá»Ÿi táº¡o LLM
    if llm_option == "Gemini":
        llm = get_gemini_llm()
    else:
        llm = get_deepseek_llm()

    # Khá»Ÿi táº¡o chain náº¿u cÃ³ vector store
    chain = None
    if st.session_state.get('vector_store'):
        chain = create_conversational_chain(st.session_state.vector_store, llm)

    # Ná»™i dung chÃ­nh
    if not st.session_state.messages and st.session_state.first_visit:
        # Trang chÃ o má»«ng
        st.markdown("### ğŸ‘‹ ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i Chatbot TÆ° Váº¥n!")
        
        # Hiá»ƒn thá»‹ tÃ­nh nÄƒng
        display_features()
        
        # CÃ¢u há»i gá»£i Ã½
        display_quick_questions()
        
        # HÆ°á»›ng dáº«n sá»­ dá»¥ng
        st.markdown("""
        <div class="info-card">
            <h4>ğŸ’¡ CÃ¡ch sá»­ dá»¥ng hiá»‡u quáº£:</h4>
            <ul>
                <li>ğŸ¯ Äáº·t cÃ¢u há»i cá»¥ thá»ƒ vá» lÄ©nh vá»±c báº¡n quan tÃ¢m</li>
                <li>ğŸ“ Cung cáº¥p thÃ´ng tin chi tiáº¿t Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chÃ­nh xÃ¡c</li>
                <li>ğŸ”„ Tiáº¿p tá»¥c há»i Ä‘á»ƒ lÃ m rÃµ thÃªm thÃ´ng tin</li>
                <li>ğŸ“ LiÃªn há»‡ trá»±c tiáº¿p náº¿u cáº§n há»— trá»£ kháº©n cáº¥p</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat vá»›i style má»›i
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant" and "category" in message:
                # Hiá»ƒn thá»‹ badge danh má»¥c
                st.markdown(get_category_badge(message["category"]), unsafe_allow_html=True)
            st.markdown(message["content"])

    # Xá»­ lÃ½ cÃ¢u há»i gá»£i Ã½
    if hasattr(st.session_state, 'suggested_question'):
        prompt = st.session_state.suggested_question
        del st.session_state.suggested_question
    else:
        prompt = st.chat_input("ğŸ’¬ HÃ£y Ä‘áº·t cÃ¢u há»i cá»§a báº¡n...") 

    # Xá»­ lÃ½ cÃ¢u há»i
    if prompt:
        # SET first_visit = False khi cÃ³ cÃ¢u há»i Ä‘áº§u tiÃªn
        if st.session_state.first_visit:
            st.session_state.first_visit = False
        
        # Hiá»ƒn thá»‹ cÃ¢u há»i ngÆ°á»i dÃ¹ng
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # PhÃ¢n loáº¡i cÃ¢u há»i
        question_category = classify_question(prompt)

        # Xá»­ lÃ½ vÃ  tráº£ lá»i
        with st.chat_message("assistant"):
            # Hiá»ƒn thá»‹ badge danh má»¥c
            st.markdown(get_category_badge(question_category), unsafe_allow_html=True)
            
            with st.spinner("ğŸ¤” Äang phÃ¢n tÃ­ch vÃ  tÃ¬m kiáº¿m thÃ´ng tin..."):
                try:
                    if chain and st.session_state.get('vector_store'):
                        # Sá»­ dá»¥ng RAG vá»›i tÃ i liá»‡u
                        response = chain({"question": prompt})
                        answer = response["answer"]
                        
                        # Hiá»ƒn thá»‹ nguá»“n tham kháº£o
                        if response.get("source_documents"):
                            st.markdown("---")
                            with st.expander("ğŸ“š Nguá»“n tham kháº£o tá»« tÃ i liá»‡u", expanded=False):
                                for i, doc in enumerate(response["source_documents"][:3]):
                                    st.markdown(f"""
                                    **ğŸ“„ Nguá»“n {i+1}:** `{doc.metadata.get('source_file', 'N/A')}`
                                    
                                    *Ná»™i dung:* {doc.page_content[:300]}...
                                    """)
                    else:
                        # Sá»­ dá»¥ng AI thuáº§n tÃºy
                        answer = answer_from_external_api(prompt, llm, question_category)
                    
                    st.markdown(answer)
                    
                    # LÆ°u lá»‹ch sá»­
                    save_chat_history(prompt, answer, question_category)
                    
                except Exception as e:
                    error_msg = f"""
                    ğŸ”§ **Xin lá»—i, há»‡ thá»‘ng gáº·p sá»± cá»‘ ká»¹ thuáº­t**
                    
                    Vui lÃ²ng thá»­ láº¡i sau hoáº·c liÃªn há»‡ trá»±c tiáº¿p:
                    ğŸ“ **Hotline tÆ° váº¥n:** (028) 3838 5052
                    ğŸ“§ **Email:** tuyensinh@hcmulaw.edu.vn
                    
                    *MÃ£ lá»—i: {str(e)}*
                    """
                    st.error(error_msg)
                    answer = error_msg

        # LÆ°u tin nháº¯n vá»›i danh má»¥c
        st.session_state.messages.append({
            "role": "assistant", 
            "content": answer,
            "category": question_category
        })

    # Footer chuyÃªn nghiá»‡p
    st.markdown("---")
    st.markdown("""
    <div class="footer">
        <div class="footer-grid">
            <div class="footer-section">
                <h4>ğŸ›ï¸ TrÆ°á»ng Äáº¡i há»c Luáº­t TPHCM</h4>
                <p>ğŸ“ 2 Nguyá»…n Táº¥t ThÃ nh, PhÆ°á»ng 12, Quáº­n 4, TP.HCM</p>
                <p>ğŸ“ Äiá»‡n thoáº¡i: (028) 3838 5050</p>
                <p>ğŸ“§ Email: info@hcmulaw.edu.vn</p>
            </div>
            <div class="footer-section">
                <h4>ğŸ“ Hotline tÆ° váº¥n</h4>
                <p>ğŸ“ Tuyá»ƒn sinh: (028) 3838 5052</p>
                <p>ğŸ‘¥ CÃ´ng tÃ¡c SV: (028) 3838 5053</p>
                <p>ğŸ  KÃ½ tÃºc xÃ¡: (028) 3838 5054</p>
                <p>ğŸ’° Há»c phÃ­: (028) 3838 5055</p>
            </div>
            <div class="footer-section">
                <h4>ğŸŒ LiÃªn káº¿t</h4>
                <p>ğŸŒ Website: www.hcmulaw.edu.vn</p>
                <p>ğŸ“˜ Facebook: /hcmulaw</p>
                <p>ğŸ“º YouTube: /hcmulaw</p>
                <p>ğŸ“§ Zalo: 0903123456</p>
            </div>
        </div>
        <div style="text-align: center; margin-top: 1rem; padding-top: 1rem; border-top: 1px solid rgba(255,255,255,0.2);">
            <p>ğŸ¤– <strong>Chatbot TÆ° Váº¥n</strong> - PhiÃªn báº£n 2.0 | ğŸ•’ Há»— trá»£ 24/7 | ğŸ’¬ Pháº£n há»“i tá»©c thÃ¬</p>
            <p style="font-size: 0.8em; opacity: 0.8;">ÄÆ°á»£c phÃ¡t triá»ƒn bá»Ÿi Lvphung - CNTT - Äáº¡i há»c Luáº­t TPHCM</p>
        </div>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
