import streamlit as st
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain_google_genai import GoogleGenerativeAI
from langchain_openai import OpenAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
import os
from dotenv import load_dotenv
import tempfile
import json
import pandas as pd
from datetime import datetime
import re
import hashlib
import sqlite3
import streamlit_authenticator as stauth
import yaml
from yaml.loader import SafeLoader
import PyPDF2
import logging

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Chatbot T∆∞ V·∫•n - ƒêH Lu·∫≠t TPHCM",
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh n√¢ng cao
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(30, 60, 114, 0.3);
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .user-message {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 5px solid #2196f3;
    }
    .assistant-message {
        background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
        border-left: 5px solid #9c27b0;
    }
    .sidebar-info {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: 1px solid #dee2e6;
    }
    .status-success {
        background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
        color: #155724;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #28a745;
    }
    .status-error {
        background: linear-gradient(135deg, #f8d7da 0%, #f1aeb5 100%);
        color: #721c24;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #dc3545;
    }
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        text-align: center;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()
grok_api_key = os.getenv("GROK_API_KEY")
gemini_api_key = os.getenv("GEMINI_API_KEY")

# Database initialization
def init_database():
    """Kh·ªüi t·∫°o database SQLite"""
    conn = sqlite3.connect('law_chatbot.db')
    cursor = conn.cursor()
    
    # B·∫£ng ng∆∞·ªùi d√πng
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            username TEXT UNIQUE NOT NULL,
            password TEXT NOT NULL,
            full_name TEXT NOT NULL,
            email TEXT NOT NULL,
            role TEXT DEFAULT 'student',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_login TIMESTAMP
        )
    ''')
    
    # B·∫£ng l·ªãch s·ª≠ chat
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS chat_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            question TEXT NOT NULL,
            answer TEXT NOT NULL,
            category TEXT,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users (id)
        )
    ''')
    
    # B·∫£ng documents
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS documents (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            filename TEXT NOT NULL,
            file_hash TEXT NOT NULL,
            upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            uploaded_by INTEGER,
            status TEXT DEFAULT 'active',
            FOREIGN KEY (uploaded_by) REFERENCES users (id)
        )
    ''')
    
    conn.commit()
    conn.close()

# Kh·ªüi t·∫°o database
init_database()

# H√†m x√°c th·ª±c ng∆∞·ªùi d√πng
def verify_user(username, password):
    """X√°c th·ª±c ng∆∞·ªùi d√πng"""
    conn = sqlite3.connect('law_chatbot.db')
    cursor = conn.cursor()
    
    hashed_password = hashlib.sha256(password.encode()).hexdigest()
    cursor.execute('SELECT id, username, full_name, role FROM users WHERE username = ? AND password = ?', 
                   (username, hashed_password))
    user = cursor.fetchone()
    
    if user:
        # C·∫≠p nh·∫≠t last_login
        cursor.execute('UPDATE users SET last_login = CURRENT_TIMESTAMP WHERE id = ?', (user[0],))
        conn.commit()
    
    conn.close()
    return user

def register_user(username, password, full_name, email, role='student'):
    """ƒêƒÉng k√Ω ng∆∞·ªùi d√πng m·ªõi"""
    conn = sqlite3.connect('law_chatbot.db')
    cursor = conn.cursor()
    
    try:
        hashed_password = hashlib.sha256(password.encode()).hexdigest()
        cursor.execute('''
            INSERT INTO users (username, password, full_name, email, role) 
            VALUES (?, ?, ?, ?, ?)
        ''', (username, hashed_password, full_name, email, role))
        conn.commit()
        return True
    except sqlite3.IntegrityError:
        return False
    finally:
        conn.close()

def save_chat_to_db(user_id, question, answer, category):
    """L∆∞u l·ªãch s·ª≠ chat v√†o database"""
    conn = sqlite3.connect('law_chatbot.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO chat_history (user_id, question, answer, category) 
        VALUES (?, ?, ?, ?)
    ''', (user_id, question, answer, category))
    
    conn.commit()
    conn.close()

def get_user_chat_history(user_id, limit=50):
    """L·∫•y l·ªãch s·ª≠ chat c·ªßa user"""
    conn = sqlite3.connect('law_chatbot.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT question, answer, category, timestamp 
        FROM chat_history 
        WHERE user_id = ? 
        ORDER BY timestamp DESC 
        LIMIT ?
    ''', (user_id, limit))
    
    history = cursor.fetchall()
    conn.close()
    return history

# Template prompt n√¢ng cao
ENHANCED_COUNSELING_PROMPT = """
B·∫°n l√† AI T∆∞ V·∫•n Vi√™n chuy√™n nghi·ªáp c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh.

TH√îNG TIN TR∆Ø·ªúNG:
- T√™n ƒë·∫ßy ƒë·ªß: Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh
- ƒê·ªãa ch·ªâ: 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM
- Website: http://hcmulaw.edu.vn/
- Hotline: (028) 39 400 989

NGUY√äN T·∫ÆC T∆¢ V·∫§N:
1. üéØ Th√¢n thi·ªán, chuy√™n nghi·ªáp, t·∫≠n t√¨nh
2. üìö Cung c·∫•p th√¥ng tin ch√≠nh x√°c t·ª´ t√†i li·ªáu c√≥ s·∫µn
3. üí° ƒê∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ, ph√π h·ª£p
4. üîç H∆∞·ªõng d·∫´n chi ti·∫øt c√°c b∆∞·ªõc th·ª±c hi·ªán
5. ‚ù§Ô∏è Lu√¥n ƒë·ªông vi√™n v√† t·∫°o ƒë·ªông l·ª±c t√≠ch c·ª±c
6. üìû H∆∞·ªõng d·∫´n li√™n h·ªá tr·ª±c ti·∫øp khi c·∫ßn thi·∫øt

TH√îNG TIN THAM KH·∫¢O: {context}

L·ªäCH S·ª¨ H·ªòI THO·∫†I: {chat_history}

C√ÇU H·ªéI: {question}

H√ÉY TR·∫¢ L·ªúI:
- B·∫±ng ti·∫øng Vi·ªát
- C·∫•u tr√∫c r√µ r√†ng v·ªõi emoji ph√π h·ª£p
- Cung c·∫•p th√¥ng tin c·ª• th·ªÉ v√† h·ªØu √≠ch
- K·∫øt th√∫c v·ªõi l·ªùi khuy√™n ho·∫∑c b∆∞·ªõc ti·∫øp theo
"""

# Kh·ªüi t·∫°o embeddings v·ªõi x·ª≠ l√Ω l·ªói
@st.cache_resource
def load_embeddings():
    """Load embeddings v·ªõi x·ª≠ l√Ω l·ªói v√† fallback"""
    try:
        # Th·ª≠ model ti·∫øng Vi·ªát t·ªët nh·∫•t
        return HuggingFaceEmbeddings(
            model_name="keepitreal/vietnamese-sbert",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
    except Exception as e:
        logger.warning(f"Kh√¥ng th·ªÉ load vietnamese-sbert: {e}")
        try:
            # Fallback sang model kh√°c
            return HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
        except Exception as e2:
            logger.error(f"Kh√¥ng th·ªÉ load embeddings: {e2}")
            st.error("L·ªói kh·ªüi t·∫°o embeddings. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng.")
            return None

embeddings = load_embeddings()

# H√†m x·ª≠ l√Ω PDF c·∫£i ti·∫øn
def extract_text_from_pdf(file_path):
    """Tr√≠ch xu·∫•t text t·ª´ PDF v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p"""
    text = ""
    
    # Ph∆∞∆°ng ph√°p 1: PyPDF2
    try:
        with open(file_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        if text.strip():
            return text
    except Exception as e:
        logger.warning(f"PyPDF2 failed: {e}")
    
    # Ph∆∞∆°ng ph√°p 2: PyPDFLoader
    try:
        loader = PyPDFLoader(file_path)
        documents = loader.load()
        text = "\n".join([doc.page_content for doc in documents])
        if text.strip():
            return text
    except Exception as e:
        logger.warning(f"PyPDFLoader failed: {e}")
    
    return text

# H√†m ph√¢n lo·∫°i c√¢u h·ªèi n√¢ng cao
def classify_question_advanced(question):
    """Ph√¢n lo·∫°i c√¢u h·ªèi v·ªõi AI"""
    question_lower = question.lower()
    
    categories = {
        "Tuy·ªÉn sinh": {
            "keywords": ["tuy·ªÉn sinh", "ƒëƒÉng k√Ω", "h·ªì s∆°", "ƒëi·ªÉm chu·∫©n", "x√©t tuy·ªÉn", "k·ª≥ thi", "th·ªß t·ª•c", "ƒë·∫°i h·ªçc", "cao ƒë·∫≥ng", "li√™n th√¥ng"],
            "priority": 1
        },
        "H·ªçc ph√≠": {
            "keywords": ["h·ªçc ph√≠", "chi ph√≠", "mi·ªÖn gi·∫£m", "h·ªçc b·ªïng", "tr·ª£ c·∫•p", "t√†i ch√≠nh", "kinh ph√≠", "thanh to√°n"],
            "priority": 2
        },
        "Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o": {
            "keywords": ["ch∆∞∆°ng tr√¨nh", "m√¥n h·ªçc", "t√≠n ch·ªâ", "khoa", "ng√†nh", "th·ªùi kh√≥a bi·ªÉu", "gi·∫£ng vi√™n", "gi√°o tr√¨nh"],
            "priority": 3
        },
        "Sinh ho·∫°t sinh vi√™n": {
            "keywords": ["c√¢u l·∫°c b·ªô", "ho·∫°t ƒë·ªông", "th·ªÉ thao", "vƒÉn h√≥a", "t√¨nh nguy·ªán", "ƒëo√†n h·ªôi", "s·ª± ki·ªán"],
            "priority": 4
        },
        "H·ªó tr·ª£ sinh vi√™n": {
            "keywords": ["t∆∞ v·∫•n", "h·ªó tr·ª£", "k√Ω t√∫c x√°", "th∆∞ vi·ªán", "c∆° s·ªü v·∫≠t ch·∫•t", "ph√≤ng ban", "d·ªãch v·ª•"],
            "priority": 5
        },
        "T·ªët nghi·ªáp": {
            "keywords": ["t·ªët nghi·ªáp", "b·∫±ng c·∫•p", "th·ª±c t·∫≠p", "vi·ªác l√†m", "ngh·ªÅ nghi·ªáp", "lu·∫≠n vƒÉn", "kh√≥a lu·∫≠n"],
            "priority": 6
        }
    }
    
    best_match = None
    max_matches = 0
    
    for category, info in categories.items():
        matches = sum(1 for keyword in info["keywords"] if keyword in question_lower)
        if matches > max_matches:
            max_matches = matches
            best_match = category
    
    return best_match if best_match else "T·ªïng qu√°t"

# H√†m x·ª≠ l√Ω file n√¢ng cao
def process_uploaded_files_enhanced(uploaded_files):
    """X·ª≠ l√Ω file v·ªõi nhi·ªÅu c·∫£i ti·∫øn"""
    documents = []
    processed_files = []
    error_files = []
    
    supported_extensions = {'.pdf': 'PDF', '.docx': 'Word', '.txt': 'Text'}
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, file in enumerate(uploaded_files):
        file_extension = f".{file.name.split('.')[-1].lower()}"
        
        # C·∫≠p nh·∫≠t progress
        progress = (i + 1) / len(uploaded_files)
        progress_bar.progress(progress)
        status_text.text(f"ƒêang x·ª≠ l√Ω: {file.name}")
        
        if file_extension not in supported_extensions:
            error_files.append(f"{file.name} - ƒê·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£")
            continue
        
        try:
            # T·∫°o hash ƒë·ªÉ ki·ªÉm tra tr√πng l·∫∑p
            file_content = file.read()
            file_hash = hashlib.md5(file_content).hexdigest()
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
                temp_file.write(file_content)
                temp_file_path = temp_file.name

            # X·ª≠ l√Ω theo lo·∫°i file
            if file_extension == ".pdf":
                text_content = extract_text_from_pdf(temp_file_path)
                if not text_content.strip():
                    error_files.append(f"{file.name} - Kh√¥ng th·ªÉ tr√≠ch xu·∫•t text t·ª´ PDF")
                    continue
                
                # T·∫°o document object
                from langchain.schema import Document
                doc = Document(
                    page_content=text_content,
                    metadata={
                        'source_file': file.name,
                        'file_type': 'PDF',
                        'file_hash': file_hash,
                        'upload_time': datetime.now().isoformat(),
                        'processed_by': 'enhanced_pdf_processor'
                    }
                )
                documents.append(doc)
                
            elif file_extension == ".docx":
                loader = Docx2txtLoader(temp_file_path)
                docs = loader.load()
                for doc in docs:
                    doc.metadata.update({
                        'source_file': file.name,
                        'file_type': 'Word',
                        'file_hash': file_hash,
                        'upload_time': datetime.now().isoformat()
                    })
                documents.extend(docs)
                
            elif file_extension == ".txt":
                loader = TextLoader(temp_file_path, encoding='utf-8')
                docs = loader.load()
                for doc in docs:
                    doc.metadata.update({
                        'source_file': file.name,
                        'file_type': 'Text',
                        'file_hash': file_hash,
                        'upload_time': datetime.now().isoformat()
                    })
                documents.extend(docs)
            
            processed_files.append(file.name)
            os.unlink(temp_file_path)
            
        except Exception as e:
            error_files.append(f"{file.name} - L·ªói: {str(e)}")
            logger.error(f"Error processing {file.name}: {e}")

    progress_bar.empty()
    status_text.empty()
    
    return documents, processed_files, error_files

# H√†m t·∫°o vector store c·∫£i ti·∫øn
def create_enhanced_vector_store(documents):
    """T·∫°o vector store v·ªõi x·ª≠ l√Ω t·ªëi ∆∞u"""
    if not documents or not embeddings:
        return None
    
    try:
        # Text splitter t·ªëi ∆∞u cho ti·∫øng Vi·ªát
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,  # Gi·∫£m chunk size ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
            chunk_overlap=100,  # TƒÉng overlap
            separators=['\n\n', '\n', '.', '!', '?', ';', ':', ' ', ''],
            length_function=len,
        )
        
        # Split documents
        texts = text_splitter.split_documents(documents)
        
        # L·ªçc v√† l√†m s·∫°ch chunks
        clean_texts = []
        for text in texts:
            content = text.page_content.strip()
            # Lo·∫°i b·ªè chunks qu√° ng·∫Øn ho·∫∑c ch·ªâ ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát
            if len(content) > 30 and not re.match(r'^[\s\W]*$', content):
                clean_texts.append(text)
        
        if not clean_texts:
            st.warning("Kh√¥ng c√≥ n·ªôi dung h·ª£p l·ªá ƒë·ªÉ t·∫°o vector store")
            return None
        
        # T·∫°o vector store
        vector_store = FAISS.from_documents(clean_texts, embeddings)
        
        logger.info(f"Created vector store with {len(clean_texts)} chunks")
        return vector_store
        
    except Exception as e:
        logger.error(f"Error creating vector store: {e}")
        st.error(f"L·ªói t·∫°o vector store: {str(e)}")
        return None

# H√†m t·∫°o conversational chain n√¢ng cao
def create_enhanced_conversational_chain(vector_store, llm):
    """T·∫°o conversational chain v·ªõi prompt t·ªëi ∆∞u"""
    if not vector_store:
        return None
    
    prompt = PromptTemplate(
        template=ENHANCED_COUNSELING_PROMPT,
        input_variables=["context", "chat_history", "question"]
    )
    
    memory = ConversationBufferWindowMemory(
        k=10,  # TƒÉng memory window
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 4, "fetch_k": 8}  # T·ªëi ∆∞u retrieval
        ),
        memory=memory,
        return_source_documents=True,
        combine_docs_chain_kwargs={"prompt": prompt},
        verbose=False
    )

# LLM v·ªõi x·ª≠ l√Ω l·ªói
@st.cache_resource
def get_enhanced_gemini_llm():
    """Kh·ªüi t·∫°o Gemini LLM v·ªõi x·ª≠ l√Ω l·ªói"""
    try:
        return GoogleGenerativeAI(
            model="gemini-1.5-flash",
            google_api_key=gemini_api_key,
            temperature=0.2,  # Gi·∫£m temperature ƒë·ªÉ tƒÉng t√≠nh nh·∫•t qu√°n
            max_output_tokens=1500
        )
    except Exception as e:
        logger.error(f"Error initializing Gemini: {e}")
        return None

@st.cache_resource
def get_enhanced_grok_llm():
    """Kh·ªüi t·∫°o Grok LLM v·ªõi x·ª≠ l√Ω l·ªói"""
    try:
        return OpenAI(
            api_key=grok_api_key,
            base_url="https://api.x.ai/v1",
            model="grok-beta",
            temperature=0.2,
            max_tokens=1500
        )
    except Exception as e:
        logger.error(f"Error initializing Grok: {e}")
        return None

# Authentication UI
def show_login_page():
    """Hi·ªÉn th·ªã trang ƒëƒÉng nh·∫≠p"""
    st.markdown("""
    <div class="main-header">
        <h1>üîê ƒêƒÉng Nh·∫≠p H·ªá Th·ªëng</h1>
        <p>Chatbot T∆∞ V·∫•n - ƒê·∫°i h·ªçc Lu·∫≠t TPHCM</p>
    </div>
    """, unsafe_allow_html=True)
    
    tab1, tab2 = st.tabs(["ƒêƒÉng Nh·∫≠p", "ƒêƒÉng K√Ω"])
    
    with tab1:
        with st.form("login_form"):
            st.subheader("ƒêƒÉng Nh·∫≠p")
            username = st.text_input("T√™n ƒëƒÉng nh·∫≠p")
            password = st.text_input("M·∫≠t kh·∫©u", type="password")
            submit = st.form_submit_button("ƒêƒÉng Nh·∫≠p", type="primary")
            
            if submit:
                if username and password:
                    user = verify_user(username, password)
                    if user:
                        st.session_state.user_id = user[0]
                        st.session_state.username = user[1]
                        st.session_state.full_name = user[2]
                        st.session_state.role = user[3]
                        st.session_state.authenticated = True
                        st.success(f"Ch√†o m·ª´ng {user[2]}!")
                        st.rerun()
                    else:
                        st.error("T√™n ƒëƒÉng nh·∫≠p ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng!")
                else:
                    st.warning("Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin!")
    
    with tab2:
        with st.form("register_form"):
            st.subheader("ƒêƒÉng K√Ω T√†i Kho·∫£n")
            new_username = st.text_input("T√™n ƒëƒÉng nh·∫≠p m·ªõi")
            new_password = st.text_input("M·∫≠t kh·∫©u", type="password")
            confirm_password = st.text_input("X√°c nh·∫≠n m·∫≠t kh·∫©u", type="password")
            full_name = st.text_input("H·ªç v√† t√™n")
            email = st.text_input("Email")
            role = st.selectbox("Vai tr√≤", ["student", "teacher", "admin"])
            
            register = st.form_submit_button("ƒêƒÉng K√Ω", type="secondary")
            
            if register:
                if all([new_username, new_password, confirm_password, full_name, email]):
                    if new_password == confirm_password:
                        if len(new_password) >= 6:
                            if register_user(new_username, new_password, full_name, email, role):
                                st.success("ƒêƒÉng k√Ω th√†nh c√¥ng! Vui l√≤ng ƒëƒÉng nh·∫≠p.")
                            else:
                                st.error("T√™n ƒëƒÉng nh·∫≠p ƒë√£ t·ªìn t·∫°i!")
                        else:
                            st.error("M·∫≠t kh·∫©u ph·∫£i c√≥ √≠t nh·∫•t 6 k√Ω t·ª±!")
                    else:
                        st.error("M·∫≠t kh·∫©u x√°c nh·∫≠n kh√¥ng kh·ªõp!")
                else:
                    st.warning("Vui l√≤ng ƒëi·ªÅn ƒë·∫ßy ƒë·ªß th√¥ng tin!")

# Main application
def show_main_app():
    """Hi·ªÉn th·ªã ·ª©ng d·ª•ng ch√≠nh"""
    # Header v·ªõi th√¥ng tin user
    col1, col2, col3 = st.columns([3, 1, 1])
    
    with col1:
        st.markdown(f"""
        <div class="main-header">
            <h1>‚öñÔ∏è Chatbot T∆∞ V·∫•n - ƒêH Lu·∫≠t TPHCM</h1>
            <p>Xin ch√†o <strong>{st.session_state.full_name}</strong> ({st.session_state.role.title()})</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        if st.button("üö™ ƒêƒÉng Xu·∫•t", type="secondary"):
            for key in ['authenticated', 'user_id', 'username', 'full_name', 'role']:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()

    # Sidebar
    with st.sidebar:
        st.header("üõ†Ô∏è C·∫•u H√¨nh H·ªá Th·ªëng")
        
        # Th√¥ng tin user
        st.markdown(f"""
        <div class="sidebar-info">
            <h4>üë§ Th√¥ng tin ng∆∞·ªùi d√πng</h4>
            <p><strong>T√™n:</strong> {st.session_state.full_name}</p>
            <p><strong>Vai tr√≤:</strong> {st.session_state.role.title()}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Upload file (ch·ªâ admin v√† teacher)
        if st.session_state.role in ['admin', 'teacher']:
            st.subheader("üìÅ T·∫£i L√™n T√†i Li·ªáu")
            uploaded_files = st.file_uploader(
                "T·∫£i l√™n t√†i li·ªáu h∆∞·ªõng d·∫´n, quy ch·∫ø...",
                accept_multiple_files=True,
                type=["pdf", "docx", "txt"],
                help="H·ªó tr·ª£ file PDF, Word v√† Text"
            )
            
            if uploaded_files and st.button("üîÑ X·ª≠ L√Ω T√†i Li·ªáu", type="primary"):
                with st.spinner("ƒêang x·ª≠ l√Ω t√†i li·ªáu..."):
                    documents, processed_files, error_files = process_uploaded_files_enhanced(uploaded_files)
                    
                    if documents:
                        st.session_state.vector_store = create_enhanced_vector_store(documents)
                        
                        if st.session_state.vector_store:
                            st.markdown(f"""
                            <div class="status-success">
                                ‚úÖ X·ª≠ l√Ω th√†nh c√¥ng {len(processed_files)} file!<br>
                                üìä T·ªïng s·ªë chunks: {st.session_state.vector_store.index.ntotal}
                            </div>
                            """, unsafe_allow_html=True)
                        else:
                            st.markdown('<div class="status-error">‚ùå Kh√¥ng th·ªÉ t·∫°o vector store</div>', unsafe_allow_html=True)
                    
                    if error_files:
                        st.warning("M·ªôt s·ªë file g·∫∑p l·ªói:")
                        for error in error_files:
                            st.write(f"‚Ä¢ {error}")

        st.divider()
        
        # L·ª±a ch·ªçn LLM
        st.subheader("ü§ñ M√¥ H√¨nh AI")
        llm_option = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["Gemini", "Grok"])
        
        # Th·ªëng k√™
        st.divider()
        st.subheader("üìä Th·ªëng K√™")
        
        if 'messages' in st.session_state:
            user_questions = len([m for m in st.session_state.messages if m["role"] == "user"])
            st.markdown(f"""
            <div class="metric-card">
                <h3>{user_questions}</h3>
                <p>C√¢u H·ªèi H√¥m Nay</p>
            </div>
            """, unsafe_allow_html=True)
        
        if st.session_state.get('vector_store'):
            chunks = st.session_state.vector_store.index.ntotal
            st.markdown(f"""
            <div class="metric-card">
                <h3>{chunks}</h3>
                <p>T√†i Li·ªáu ƒê√£ T·∫£i</p>
            </div>
            """, unsafe_allow_html=True)
        
        # L·ªãch s·ª≠ chat
        if st.button("üìú Xem L·ªãch S·ª≠ Chat"):
            show_chat_history()

    # Kh·ªüi t·∫°o session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None

    # Ki·ªÉm tra API keys
    if llm_option == "Gemini" and not gemini_api_key:
        st.error("‚ö†Ô∏è Vui l√≤ng cung c·∫•p GEMINI_API_KEY trong file .env")
        st.stop()
    elif llm_option == "Grok" and not grok_api_key:
        st.error("‚ö†Ô∏è Vui l√≤ng cung c·∫•p GROK_API_KEY trong file .env")
        st.stop()

    # Kh·ªüi t·∫°o LLM
    if llm_option == "Gemini":
        llm = get_enhanced_gemini_llm()
    else:
        llm = get_enhanced_grok_llm()
    
    if not llm:
        st.error("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o m√¥ h√¨nh AI. Vui l√≤ng ki·ªÉm tra API key.")
        st.stop()

    # Kh·ªüi t·∫°o chain n·∫øu c√≥ vector store
    chain = None
    if st.session_state.vector_store:
        chain = create_enhanced_conversational_chain(st.session_state.vector_store, llm)

    # H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng ban ƒë·∫ßu
    if not st.session_state.messages:
        welcome_message = f"""
        üëã **Ch√†o m·ª´ng {st.session_state.full_name} ƒë·∫øn v·ªõi Chatbot T∆∞ V·∫•n ƒêH Lu·∫≠t TPHCM!**
        
        üéØ **T√¥i c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n v·ªÅ:**
        - üìù **Tuy·ªÉn sinh**: Th√¥ng tin ƒëƒÉng k√Ω, h·ªì s∆°, ƒëi·ªÉm chu·∫©n
        - üí∞ **H·ªçc ph√≠**: Chi ph√≠ h·ªçc t·∫≠p, h·ªçc b·ªïng, mi·ªÖn gi·∫£m
        - üìö **Ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o**: M√¥n h·ªçc, t√≠n ch·ªâ, gi·∫£ng vi√™n
        - üé≠ **Ho·∫°t ƒë·ªông sinh vi√™n**: CLB, s·ª± ki·ªán, t√¨nh nguy·ªán
        - üè† **H·ªó tr·ª£ sinh vi√™n**: K√Ω t√∫c x√°, th∆∞ vi·ªán, c∆° s·ªü v·∫≠t ch·∫•t
        - üéì **T·ªët nghi·ªáp**: Th·ª±c t·∫≠p, vi·ªác l√†m, b·∫±ng c·∫•p
        
        üí° **G·ª£i √Ω c√¢u h·ªèi:**
        - "ƒêi·ªÅu ki·ªán x√©t tuy·ªÉn v√†o ng√†nh Lu·∫≠t nh∆∞ th·∫ø n√†o?"
        - "H·ªçc ph√≠ m·ªôt nƒÉm c·ªßa tr∆∞·ªùng l√† bao nhi√™u?"
        - "C√≥ nh·ªØng c√¢u l·∫°c b·ªô n√†o trong tr∆∞·ªùng?"
        
        üîç **L∆∞u √Ω**: H√£y ƒë·∫∑t c√¢u h·ªèi c·ª• th·ªÉ ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c h·ªó tr·ª£ t·ªët nh·∫•t!
        """
        
        st.markdown(welcome_message)

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Hi·ªÉn th·ªã metadata n·∫øu c√≥
            if "metadata" in message:
                metadata = message["metadata"]
                if metadata.get("category"):
                    st.caption(f"üè∑Ô∏è Danh m·ª•c: {metadata['category']}")
                if metadata.get("sources"):
                    with st.expander("üìö Ngu·ªìn tham kh·∫£o"):
                        for source in metadata["sources"]:
                            st.write(f"‚Ä¢ {source}")

    # Nh·∫≠p c√¢u h·ªèi
    if prompt := st.chat_input("üí¨ ƒê·∫∑t c√¢u h·ªèi c·ªßa b·∫°n..."):
        # Hi·ªÉn th·ªã c√¢u h·ªèi
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Ph√¢n lo·∫°i c√¢u h·ªèi
        question_category = classify_question_advanced(prompt)

        # X·ª≠ l√Ω v√† tr·∫£ l·ªùi
        with st.chat_message("assistant"):
            with st.spinner("ü§î ƒêang ph√¢n t√≠ch v√† t√¨m ki·∫øm th√¥ng tin..."):
                try:
                    sources = []
                    
                    if chain and st.session_state.vector_store:
                        # S·ª≠ d·ª•ng RAG v·ªõi documents
                        response = chain({"question": prompt})
                        answer = response["answer"]
                        
                        # X·ª≠ l√Ω ngu·ªìn tham kh·∫£o
                        if response.get("source_documents"):
                            sources = []
                            for doc in response["source_documents"][:3]:
                                source_info = f"{doc.metadata.get('source_file', 'N/A')} - {doc.metadata.get('file_type', 'Unknown')}"
                                if source_info not in sources:
                                    sources.append(source_info)
                            
                            # Hi·ªÉn th·ªã ngu·ªìn tham kh·∫£o
                            if sources:
                                st.markdown("---")
                                with st.expander("üìö Ngu·ªìn tham kh·∫£o"):
                                    for i, source in enumerate(sources, 1):
                                        st.write(f"**{i}.** {source}")
                                    
                                    # Hi·ªÉn th·ªã ƒëo·∫°n vƒÉn tham kh·∫£o
                                    st.markdown("**ƒêo·∫°n vƒÉn tham kh·∫£o:**")
                                    for i, doc in enumerate(response["source_documents"][:2], 1):
                                        st.write(f"*Ngu·ªìn {i}:* {doc.page_content[:300]}...")
                    else:
                        # S·ª≠ d·ª•ng LLM tr·ª±c ti·∫øp
                        enhanced_prompt = f"""
                        B·∫°n l√† t∆∞ v·∫•n vi√™n chuy√™n nghi·ªáp c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t TPHCM.
                        
                        TH√îNG TIN TR∆Ø·ªúNG:
                        - T√™n: ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh
                        - ƒê·ªãa ch·ªâ: 2 Nguy·ªÖn T·∫•t Th√†nh, P.12, Q.4, TPHCM
                        - Website: http://hcmulaw.edu.vn/
                        - Hotline: (028) 39 400 989
                        
                        Danh m·ª•c c√¢u h·ªèi: {question_category}
                        C√¢u h·ªèi: {prompt}
                        
                        H√£y tr·∫£ l·ªùi m·ªôt c√°ch chuy√™n nghi·ªáp, th√¢n thi·ªán v√† h·ªØu √≠ch.
                        S·ª≠ d·ª•ng emoji ph√π h·ª£p v√† c·∫•u tr√∫c r√µ r√†ng.
                        N·∫øu kh√¥ng c√≥ th√¥ng tin c·ª• th·ªÉ, h√£y h∆∞·ªõng d·∫´n li√™n h·ªá ph√≤ng ban ph√π h·ª£p.
                        """
                        
                        if isinstance(llm, GoogleGenerativeAI):
                            answer = llm.invoke(enhanced_prompt)
                        else:
                            answer = llm.invoke(enhanced_prompt)
                    
                    # Th√™m th√¥ng tin danh m·ª•c
                    if question_category != "T·ªïng qu√°t":
                        answer = f"**üìå Danh m·ª•c: {question_category}**\n\n{answer}"
                    
                    # Th√™m footer v·ªõi th√¥ng tin li√™n h·ªá
                    answer += f"""
                    
                    ---
                    üìû **C·∫ßn h·ªó tr·ª£ th√™m?**
                    - **Hotline**: (028) 39 400 989
                    - **Website**: http://hcmulaw.edu.vn/
                    - **ƒê·ªãa ch·ªâ**: 2 Nguy·ªÖn T·∫•t Th√†nh, P.12, Q.4, TPHCM
                    """
                    
                    st.markdown(answer)
                    
                    # L∆∞u v√†o database
                    if hasattr(st.session_state, 'user_id'):
                        save_chat_to_db(st.session_state.user_id, prompt, answer, question_category)
                    
                except Exception as e:
                    logger.error(f"Error generating response: {e}")
                    error_msg = f"""
                    üòî **Xin l·ªói, t√¥i g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t!**
                    
                    Vui l√≤ng:
                    - Th·ª≠ l·∫°i c√¢u h·ªèi sau √≠t ph√∫t
                    - Ho·∫∑c li√™n h·ªá tr·ª±c ti·∫øp v·ªõi ph√≤ng t∆∞ v·∫•n
                    
                    üìû **Hotline h·ªó tr·ª£**: (028) 39 400 989
                    
                    *M√£ l·ªói: {str(e)[:100]}*
                    """
                    st.error(error_msg)
                    answer = error_msg

        # L∆∞u tin nh·∫Øn v·ªõi metadata
        message_metadata = {
            "category": question_category,
            "sources": sources,
            "timestamp": datetime.now().isoformat()
        }
        
        st.session_state.messages.append({
            "role": "assistant", 
            "content": answer,
            "metadata": message_metadata
        })

    # C√°c n√∫t ch·ª©c nƒÉng b·ªï sung
    st.markdown("---")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("üîÑ L√†m m·ªõi cu·ªôc tr√≤ chuy·ªán"):
            st.session_state.messages = []
            st.rerun()
    
    with col2:
        if st.button("üì• Xu·∫•t l·ªãch s·ª≠ chat"):
            export_chat_history()
    
    with col3:
        if st.button("üéØ C√¢u h·ªèi g·ª£i √Ω"):
            show_suggested_questions()
    
    with col4:
        if st.button("üìä Th·ªëng k√™ chi ti·∫øt"):
            show_detailed_stats()

def show_chat_history():
    """Hi·ªÉn th·ªã l·ªãch s·ª≠ chat c·ªßa user"""
    if hasattr(st.session_state, 'user_id'):
        history = get_user_chat_history(st.session_state.user_id)
        
        if history:
            st.subheader("üìú L·ªãch S·ª≠ Chat")
            for i, (question, answer, category, timestamp) in enumerate(history[:10]):
                with st.expander(f"üí¨ {question[:50]}... - {timestamp[:10]}"):
                    st.write(f"**üè∑Ô∏è Danh m·ª•c:** {category}")
                    st.write(f"**‚ùì C√¢u h·ªèi:** {question}")
                    st.write(f"**üí° Tr·∫£ l·ªùi:** {answer[:200]}...")
                    st.write(f"**‚è∞ Th·ªùi gian:** {timestamp}")
        else:
            st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ chat n√†o.")

def export_chat_history():
    """Xu·∫•t l·ªãch s·ª≠ chat ra file"""
    if st.session_state.messages:
        chat_data = []
        for msg in st.session_state.messages:
            chat_data.append({
                'Role': msg['role'],
                'Content': msg['content'],
                'Timestamp': datetime.now().isoformat()
            })
        
        df = pd.DataFrame(chat_data)
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        
        st.download_button(
            label="üì• T·∫£i xu·ªëng l·ªãch s·ª≠ chat",
            data=csv,
            file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )

def show_suggested_questions():
    """Hi·ªÉn th·ªã c√¢u h·ªèi g·ª£i √Ω"""
    st.subheader("üéØ C√¢u H·ªèi G·ª£i √ù")
    
    suggestions = {
        "Tuy·ªÉn sinh": [
            "ƒêi·ªÅu ki·ªán x√©t tuy·ªÉn v√†o ng√†nh Lu·∫≠t nh∆∞ th·∫ø n√†o?",
            "H·ªì s∆° ƒëƒÉng k√Ω x√©t tuy·ªÉn g·ªìm nh·ªØng g√¨?",
            "ƒêi·ªÉm chu·∫©n nƒÉm ngo√°i c·ªßa c√°c ng√†nh l√† bao nhi√™u?",
            "C√≥ nh·ªØng ph∆∞∆°ng th·ª©c x√©t tuy·ªÉn n√†o?"
        ],
        "H·ªçc ph√≠": [
            "H·ªçc ph√≠ m·ªôt nƒÉm c·ªßa tr∆∞·ªùng l√† bao nhi√™u?",
            "C√≥ ch√≠nh s√°ch mi·ªÖn gi·∫£m h·ªçc ph√≠ kh√¥ng?",
            "L√†m th·∫ø n√†o ƒë·ªÉ xin h·ªçc b·ªïng?",
            "C√≥ th·ªÉ tr·∫£ h·ªçc ph√≠ theo ƒë·ª£t kh√¥ng?"
        ],
        "Sinh ho·∫°t": [
            "C√≥ nh·ªØng c√¢u l·∫°c b·ªô n√†o trong tr∆∞·ªùng?",
            "Ho·∫°t ƒë·ªông ngo·∫°i kh√≥a c√≥ g√¨ th√∫ v·ªã?",
            "L√†m sao ƒë·ªÉ tham gia ƒëo√†n thanh ni√™n?",
            "C√≥ ch∆∞∆°ng tr√¨nh t√¨nh nguy·ªán n√†o kh√¥ng?"
        ]
    }
    
    for category, questions in suggestions.items():
        st.write(f"**{category}:**")
        for q in questions:
            if st.button(q, key=f"suggest_{hash(q)}"):
                st.session_state.suggested_question = q
                st.rerun()

def show_detailed_stats():
    """Hi·ªÉn th·ªã th·ªëng k√™ chi ti·∫øt"""
    st.subheader("üìä Th·ªëng K√™ Chi Ti·∫øt")
    
    if hasattr(st.session_state, 'user_id'):
        history = get_user_chat_history(st.session_state.user_id, 100)
        
        if history:
            # Th·ªëng k√™ theo danh m·ª•c
            categories = [h[2] for h in history if h[2]]
            if categories:
                category_counts = pd.Series(categories).value_counts()
                
                st.write("**Ph√¢n b·ªë c√¢u h·ªèi theo danh m·ª•c:**")
                for cat, count in category_counts.items():
                    st.write(f"‚Ä¢ {cat}: {count} c√¢u h·ªèi")
            
            # Th·ªëng k√™ theo th·ªùi gian
            dates = [h[3][:10] for h in history]
            if dates:
                date_counts = pd.Series(dates).value_counts().sort_index()
                st.write("**Ho·∫°t ƒë·ªông theo ng√†y:**")
                for date, count in date_counts.head(7).items():
                    st.write(f"‚Ä¢ {date}: {count} c√¢u h·ªèi")

# Main function
def main():
    """H√†m main ƒëi·ªÅu khi·ªÉn lu·ªìng ·ª©ng d·ª•ng"""
    
    # Ki·ªÉm tra authentication
    if not st.session_state.get('authenticated', False):
        show_login_page()
    else:
        show_main_app()
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; font-size: 0.9em; padding: 1rem;">
        üèõÔ∏è <strong>Tr∆∞·ªùng ƒê·∫°i h·ªçc Lu·∫≠t Th√†nh ph·ªë H·ªì Ch√≠ Minh</strong><br>
        üìç 2 Nguy·ªÖn T·∫•t Th√†nh, Ph∆∞·ªùng 12, Qu·∫≠n 4, TP.HCM<br>
        üìû Hotline: (028) 39 400 989 | üåê Website: http://hcmulaw.edu.vn/<br>
        ü§ñ <em>ƒê∆∞·ª£c h·ªó tr·ª£ b·ªüi AI - Phi√™n b·∫£n n√¢ng cao v·ªõi x√°c th·ª±c ng∆∞·ªùi d√πng</em>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()